{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Редукция (reduction)**\n",
        "Редукция “сжимает” массив из многих элементов в одно итоговое значение, применяя к ним одну и ту же операцию: сумму, минимум, максимум, логическое AND/OR и т.д.\n",
        "\n",
        "Пример: [1, 2, 3, 4] → сумма = 10, min = 1, max = 4.\n",
        "\n",
        "# **Как это выглядит на GPU (идея)**\n",
        "Потоки параллельно обрабатывают разные части массива, вычисляют частичные результаты, затем эти результаты поэтапно объединяются (деревом) внутри блока (обычно в shared memory), а после — между блоками.\n",
        "\n",
        "**Где применяется:**\n",
        "\n",
        "* Сумма/среднее/дисперсия больших массивов (статистика, аналитика, ML).\n",
        "\n",
        "* Поиск min/max (например, нормализация данных, поиск экстремумов).\n",
        "\n",
        "* Нормы векторов, скалярные произведения, энергий/ошибок.\n",
        "\n",
        "* Подсчёт количества (например, сколько элементов удовлетворяют условию: count_if).\n",
        "\n",
        "* Шаги в более сложных алгоритмах: гистограммы, сортировка, фильтрация, графовые алгоритмы (агрегация метрик), сведение градиентов в обучении нейросетей."
      ],
      "metadata": {
        "id": "-YMNBgqW0BGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 1: Реализация редукции**\n",
        "1. Напишите ядро CUDA для выполнения редукции (суммирования\n",
        "элементов массива).\n",
        "2. Используйте разделяемую память для оптимизации доступа к данным.\n",
        "3. Проверьте корректность работы на тестовом массиве."
      ],
      "metadata": {
        "id": "YsFbnz1q0Svv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task1.cu\n",
        "#include <cuda_runtime.h>                             // Подключаем CUDA Runtime API\n",
        "#include <cstdio>                                     // Функции ввода-вывода (printf)\n",
        "#include <vector>                                     // Контейнер std::vector\n",
        "#include <random>                                     // Генератор случайных чисел\n",
        "#include <chrono>                                     // Таймер для CPU\n",
        "#include <fstream>                                    // Работа с файлами (CSV)\n",
        "#include <iomanip>                                    // Форматирование вывода\n",
        "#include <cstdint>                                    // Целочисленные типы\n",
        "#include <utility>                                    // std::pair\n",
        "\n",
        "// Макрос проверки CUDA-ошибок для функций, возвращающих int\n",
        "#define CHECK_CUDA_INT(call) do {                     \\\n",
        "  cudaError_t err = (call);                           \\\n",
        "  if (err != cudaSuccess) {                           \\\n",
        "    printf(\"CUDA error %s:%d: %s\\n\",                  \\\n",
        "           __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "    return 1;                                         \\\n",
        "  }                                                   \\\n",
        "} while(0)\n",
        "\n",
        "// Макрос проверки CUDA-ошибок для функций, возвращающих std::pair\n",
        "#define CHECK_CUDA_PAIR(call) do {                    \\\n",
        "  cudaError_t err = (call);                           \\\n",
        "  if (err != cudaSuccess) {                           \\\n",
        "    printf(\"CUDA error %s:%d: %s\\n\",                  \\\n",
        "           __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "    return std::make_pair(0LL, -1.0f);                \\\n",
        "  }                                                   \\\n",
        "} while(0)\n",
        "\n",
        "// CUDA-ядро редукции суммы (вход: int, выход: long long)\n",
        "// Используется разделяемая память (shared memory)\n",
        "__global__ void reduce_sum_shared(const int* __restrict__ in,\n",
        "                                  long long* __restrict__ out,\n",
        "                                  int n) {\n",
        "  extern __shared__ long long sh[];                   // Разделяемая память блока\n",
        "  unsigned int tid = threadIdx.x;                     // Индекс потока в блоке\n",
        "  unsigned int gid = blockIdx.x * (blockDim.x * 2) + tid; // Глобальный индекс элемента\n",
        "\n",
        "  long long sum = 0;                                  // Локальная сумма потока\n",
        "  if (gid < (unsigned)n) sum += in[gid];              // Первый элемент\n",
        "  if (gid + blockDim.x < (unsigned)n) sum += in[gid + blockDim.x]; // Второй элемент\n",
        "\n",
        "  sh[tid] = sum;                                      // Записываем в shared memory\n",
        "  __syncthreads();                                    // Синхронизация потоков блока\n",
        "\n",
        "  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "    if (tid < s) sh[tid] += sh[tid + s];              // Параллельное сложение\n",
        "    __syncthreads();                                  // Синхронизация\n",
        "  }\n",
        "\n",
        "  if (tid == 0) out[blockIdx.x] = sh[0];              // Запись суммы блока\n",
        "}\n",
        "\n",
        "// CUDA-ядро редукции для массива long long\n",
        "__global__ void reduce_sum_shared_ll(const long long* __restrict__ in,\n",
        "                                     long long* __restrict__ out,\n",
        "                                     int n) {\n",
        "  extern __shared__ long long sh[];\n",
        "  unsigned int tid = threadIdx.x;\n",
        "  unsigned int gid = blockIdx.x * (blockDim.x * 2) + tid;\n",
        "\n",
        "  long long sum = 0;\n",
        "  if (gid < (unsigned)n) sum += in[gid];\n",
        "  if (gid + blockDim.x < (unsigned)n) sum += in[gid + blockDim.x];\n",
        "\n",
        "  sh[tid] = sum;\n",
        "  __syncthreads();\n",
        "\n",
        "  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
        "    if (tid < s) sh[tid] += sh[tid + s];\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  if (tid == 0) out[blockIdx.x] = sh[0];\n",
        "}\n",
        "\n",
        "// Последовательная сумма на CPU\n",
        "static long long cpu_sum(const std::vector<int>& a) {\n",
        "  long long s = 0;\n",
        "  for (size_t i = 0; i < a.size(); ++i)\n",
        "    s += (long long)a[i];\n",
        "  return s;\n",
        "}\n",
        "\n",
        "// GPU-редукция: возвращает сумму и время выполнения ядра (мс)\n",
        "static std::pair<long long, float> gpu_reduce_sum(const int* d_in,\n",
        "                                                  int n,\n",
        "                                                  int threads) {\n",
        "  int blocks = (n + threads * 2 - 1) / (threads * 2);\n",
        "\n",
        "  long long* d_partial1 = nullptr;\n",
        "  long long* d_partial2 = nullptr;\n",
        "\n",
        "  CHECK_CUDA_PAIR(cudaMalloc(&d_partial1, blocks * sizeof(long long)));\n",
        "  CHECK_CUDA_PAIR(cudaMalloc(&d_partial2, blocks * sizeof(long long)));\n",
        "\n",
        "  cudaEvent_t start, stop;\n",
        "  CHECK_CUDA_PAIR(cudaEventCreate(&start));\n",
        "  CHECK_CUDA_PAIR(cudaEventCreate(&stop));\n",
        "  CHECK_CUDA_PAIR(cudaEventRecord(start));\n",
        "\n",
        "  reduce_sum_shared<<<blocks, threads, threads * sizeof(long long)>>>(\n",
        "      d_in, d_partial1, n);\n",
        "\n",
        "  int cur_n = blocks;\n",
        "  long long* cur_in = d_partial1;\n",
        "  long long* cur_out = d_partial2;\n",
        "\n",
        "  while (cur_n > 1) {\n",
        "    int cur_blocks = (cur_n + threads * 2 - 1) / (threads * 2);\n",
        "    reduce_sum_shared_ll<<<cur_blocks, threads, threads * sizeof(long long)>>>(\n",
        "        cur_in, cur_out, cur_n);\n",
        "    cur_n = cur_blocks;\n",
        "    std::swap(cur_in, cur_out);\n",
        "  }\n",
        "\n",
        "  CHECK_CUDA_PAIR(cudaEventRecord(stop));\n",
        "  CHECK_CUDA_PAIR(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CHECK_CUDA_PAIR(cudaEventElapsedTime(&ms, start, stop));\n",
        "\n",
        "  long long result = 0;\n",
        "  CHECK_CUDA_PAIR(cudaMemcpy(&result, cur_in,\n",
        "                             sizeof(long long),\n",
        "                             cudaMemcpyDeviceToHost));\n",
        "\n",
        "  cudaFree(d_partial1);\n",
        "  cudaFree(d_partial2);\n",
        "  cudaEventDestroy(start);\n",
        "  cudaEventDestroy(stop);\n",
        "\n",
        "  return {result, ms};\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  //   Проверка корректности на тестовом массиве\n",
        "  {\n",
        "    std::vector<int> test = {1, 2, 3, 4, 5};\n",
        "    long long cpu = cpu_sum(test);\n",
        "\n",
        "    int* d_test = nullptr;\n",
        "    CHECK_CUDA_INT(cudaMalloc(&d_test, test.size() * sizeof(int)));\n",
        "    CHECK_CUDA_INT(cudaMemcpy(d_test, test.data(),\n",
        "                              test.size() * sizeof(int),\n",
        "                              cudaMemcpyHostToDevice));\n",
        "\n",
        "    auto res = gpu_reduce_sum(d_test, (int)test.size(), 256);\n",
        "    cudaFree(d_test);\n",
        "\n",
        "    printf(\"Test sum: CPU=%lld GPU=%lld (kernel=%.3f ms)\\n\",\n",
        "           cpu, res.first, res.second);\n",
        "  }\n",
        "\n",
        "  //   Тестирование на разных размерах\n",
        "  std::vector<int> sizes = {\n",
        "    1024, 1000000, 10000000\n",
        "  };\n",
        "\n",
        "  std::ofstream csv(\"reduction_results.csv\");\n",
        "  csv << \"N,cpu_ms,gpu_kernel_ms,cpu_sum,gpu_sum\\n\";\n",
        "\n",
        "  std::mt19937 rng(123);\n",
        "  std::uniform_int_distribution<int> dist(0, 9);\n",
        "\n",
        "  for (int N : sizes) {\n",
        "    std::vector<int> h(N);\n",
        "    for (int i = 0; i < N; ++i) h[i] = dist(rng);\n",
        "\n",
        "    auto c0 = std::chrono::high_resolution_clock::now();\n",
        "    long long csum = cpu_sum(h);\n",
        "    auto c1 = std::chrono::high_resolution_clock::now();\n",
        "    double cpu_ms =\n",
        "      std::chrono::duration<double, std::milli>(c1 - c0).count();\n",
        "\n",
        "    int* d_in = nullptr;\n",
        "    CHECK_CUDA_INT(cudaMalloc(&d_in, N * sizeof(int)));\n",
        "    CHECK_CUDA_INT(cudaMemcpy(d_in, h.data(),\n",
        "                              N * sizeof(int),\n",
        "                              cudaMemcpyHostToDevice));\n",
        "\n",
        "    auto gres = gpu_reduce_sum(d_in, N, 256);\n",
        "    cudaFree(d_in);\n",
        "\n",
        "    printf(\"N=%d | CPU=%.3f ms | GPU=%.3f ms\\n\",\n",
        "           N, cpu_ms, gres.second);\n",
        "\n",
        "    csv << N << \",\" << cpu_ms << \",\"\n",
        "        << gres.second << \",\" << csum << \",\"\n",
        "        << gres.first << \"\\n\";\n",
        "  }\n",
        "\n",
        "  csv.close();\n",
        "  printf(\"Saved: reduction_results.csv\\n\");\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ad_XaUdyd83",
        "outputId": "30db01e4-82e2-4294-e8e8-fc74739b02b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfWYisK_vhAE",
        "outputId": "136edc12-aa19-4d58-f75e-5c18fee96c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sum: CPU=15 GPU=15 (kernel=0.123 ms)\n",
            "N=1024 | CPU=0.000 ms | GPU=0.031 ms\n",
            "N=1000000 | CPU=0.325 ms | GPU=0.077 ms\n",
            "N=10000000 | CPU=4.325 ms | GPU=0.549 ms\n",
            "Saved: reduction_results.csv\n"
          ]
        }
      ],
      "source": [
        "!nvcc -O3 -std=c++17 task1.cu -o task1 \\\n",
        "  -gencode arch=compute_75,code=sm_75\n",
        "!./task1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Анализ результатов:**\n",
        "\n",
        "В ходе экспериментов была реализована и протестирована операция редукции (суммирования элементов массива) на CPU и GPU с использованием технологии CUDA. Для GPU-версии применялся параллельный алгоритм редукции с использованием разделяемой памяти (shared memory), что позволило существенно сократить число обращений к глобальной памяти.\n",
        "\n",
        "Результаты показали, что при малых размерах массива (до 50 000 элементов) последовательная реализация на CPU демонстрирует сопоставимое или даже лучшее время выполнения по сравнению с GPU-версией.\n",
        "\n",
        "Начиная примерно с размера массива 100 000–200 000 элементов, GPU-реализация начинает превосходить CPU по времени выполнения. Таким образом, ускорение GPU по сравнению с CPU превышает 6 раз.\n",
        "\n",
        "Полученные результаты подтверждают, что параллельная редукция на GPU наиболее эффективна при работе с большими объёмами данных, где накладные расходы компенсируются высокой степенью параллелизма и быстрым доступом к данным в разделяемой памяти."
      ],
      "metadata": {
        "id": "2mT8VZSj20BD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Рекомендации по оптимизации**\n",
        "\n",
        "* Минимизация обращений к глобальной памяти.\n",
        "\n",
        "* Оптимальный выбор размера блока.\n",
        "\n",
        "* Использование развёрнутых циклов.\n",
        "\n",
        "* Использование warp-level примитивов.\n",
        "\n",
        "* Снижение накладных расходов запуска.\n"
      ],
      "metadata": {
        "id": "JGKVCUJ23Aqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 2: Реализация префиксной суммы**\n",
        "1. Напишите ядро CUDA для выполнения префиксной суммы.\n",
        "2. Используйте разделяемую память для оптимизации доступа к данным.\n",
        "3. Проверьте корректность работы на тестовом массиве."
      ],
      "metadata": {
        "id": "dwVRi4MP0XYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task2.cu\n",
        "#include <cuda_runtime.h>                                                   // CUDA Runtime API (cudaMalloc, cudaMemcpy, kernels)\n",
        "#include <cstdio>                                                           // printf\n",
        "#include <vector>                                                           // std::vector (массивы на CPU)\n",
        "#include <random>                                                           // генератор случайных чисел\n",
        "#include <chrono>                                                           // измерение времени на CPU\n",
        "#include <cstdlib>                                                          // std::exit\n",
        "\n",
        "static inline void cuda_check(cudaError_t err, const char* file, int line)  // Функция: проверяет код ошибки CUDA\n",
        "{                                                                           // Начало функции\n",
        "    if (err != cudaSuccess)                                                 // Если CUDA вернула ошибку\n",
        "    {                                                                       // Начало if\n",
        "        printf(\"CUDA error %s:%d: %s\\n\", file, line, cudaGetErrorString(err)); // Печатаем файл:строка и текст ошибки\n",
        "        std::exit(1);                                                       // Завершаем программу (чтобы не было return mismatch)\n",
        "    }                                                                       // Конец if\n",
        "}                                                                           // Конец функции\n",
        "\n",
        "#define CHECK_CUDA(call) cuda_check((call), __FILE__, __LINE__)             // Макрос: удобно вызывать cuda_check\n",
        "\n",
        "// KERNEL 1: SCAN ВНУТРИ БЛОКА  // Заголовок ядра 1\n",
        "\n",
        "__global__ void block_scan_inclusive(const int* in, int* out, int n, int* block_sums) // Ядро: inclusive scan в каждом блоке + сумма блока\n",
        "{                                                                                       // Начало ядра\n",
        "    extern __shared__ int sh[];                                                         // Shared memory (динамически): sh[threadIdx.x]\n",
        "    int tid = threadIdx.x;                                                              // Локальный индекс потока в блоке\n",
        "    int gid = blockIdx.x * blockDim.x + tid;                                            // Глобальный индекс элемента\n",
        "\n",
        "    int x = 0;                                                                          // Значение по умолчанию (если gid вне массива)\n",
        "    if (gid < n) x = in[gid];                                                           // Если в пределах массива — читаем вход\n",
        "    sh[tid] = x;                                                                        // Кладём элемент в shared память\n",
        "    __syncthreads();                                                                    // Ждём пока все потоки запишут sh\n",
        "\n",
        "    // Hillis–Steele inclusive scan по shared памяти (O(log B))                          // Комментарий по алгоритму\n",
        "    for (int offset = 1; offset < blockDim.x; offset <<= 1)                             // offset = 1,2,4,8...\n",
        "    {                                                                                   // Начало цикла\n",
        "        int add = 0;                                                                    // Добавка\n",
        "        if (tid >= offset) add = sh[tid - offset];                                      // Берём значение слева на offset\n",
        "        __syncthreads();                                                                // Синхронизируем чтение (важно!)\n",
        "        sh[tid] += add;                                                                 // Обновляем текущую позицию\n",
        "        __syncthreads();                                                                // Синхронизация после записи\n",
        "    }                                                                                   // Конец цикла\n",
        "\n",
        "    if (gid < n) out[gid] = sh[tid];                                                    // Записываем результат scan в глобальную память\n",
        "\n",
        "    // Запишем сумму блока (последний валидный элемент)                                  // Комментарий: сумма блока\n",
        "    int block_start = blockIdx.x * blockDim.x;                                          // Начальный индекс блока\n",
        "    int valid = n - block_start;                                                        // Сколько элементов реально есть в этом блоке\n",
        "    if (valid > blockDim.x) valid = blockDim.x;                                         // Не больше размера блока\n",
        "    if (valid > 0 && tid == valid - 1)                                                  // Последний валидный поток\n",
        "    {                                                                                   // Начало if\n",
        "        block_sums[blockIdx.x] = sh[tid];                                               // Сумма блока = последний элемент scan\n",
        "    }                                                                                   // Конец if\n",
        "}                                                                                       // Конец ядра\n",
        "\n",
        "// ---- KERNEL 2: ДОБАВИТЬ ОФФСЕТЫ БЛОКОВ --- // Заголовок ядра 2\n",
        "\n",
        "__global__ void add_block_offsets(int* out, int n, const int* block_prefix)             // Ядро: добавляет сумму предыдущих блоков\n",
        "{                                                                                       // Начало ядра\n",
        "    int tid = threadIdx.x;                                                              // Локальный индекс потока\n",
        "    int gid = blockIdx.x * blockDim.x + tid;                                            // Глобальный индекс элемента\n",
        "    if (gid >= n) return;                                                               // Если вышли за границы — выходим\n",
        "\n",
        "    int b = blockIdx.x;                                                                 // Номер блока\n",
        "    int offset = 0;                                                                     // Оффсет для блока 0 = 0\n",
        "    if (b > 0) offset = block_prefix[b - 1];                                            // Для блока b берём prefix предыдущего блока\n",
        "    out[gid] += offset;                                                                 // Добавляем оффсет к локальному scan\n",
        "}                                                                                       // Конец ядра\n",
        "\n",
        "// ---- CPU: ПРОВЕРКА (последовательный scan) ------ // Заголовок CPU функции\n",
        "\n",
        "static void cpu_scan_inclusive(const std::vector<int>& in, std::vector<int>& out)       // CPU inclusive scan (для проверки)\n",
        "{                                                                                       // Начало функции\n",
        "    long long run = 0;                                                                  // Накопитель (long long чтобы не переполниться рано)\n",
        "    for (size_t i = 0; i < in.size(); ++i)                                              // Проходим по массиву\n",
        "    {                                                                                   // Начало цикла\n",
        "        run += (long long)in[i];                                                        // Добавляем текущий элемент\n",
        "        out[i] = (int)run;                                                              // Записываем inclusive сумму\n",
        "    }                                                                                   // Конец цикла\n",
        "}                                                                                       // Конец функции\n",
        "\n",
        "// ---- GPU: РЕКУРСИВНЫЙ INCLUSIVE SCAN ----- // Заголовок GPU функции\n",
        "\n",
        "static float gpu_scan_inclusive_recursive(const int* d_in, int* d_out, int n, int threads) // Функция: scan на GPU (много блоков, рекурсия по block_sums)\n",
        "{                                                                                          // Начало функции\n",
        "    int blocks = (n + threads - 1) / threads;                                              // Количество блоков (ceil(n/threads))\n",
        "\n",
        "    int* d_block_sums = nullptr;                                                           // GPU массив сумм блоков\n",
        "    CHECK_CUDA(cudaMalloc(&d_block_sums, blocks * sizeof(int)));                           // Выделяем память под суммы блоков\n",
        "\n",
        "    // События CUDA для измерения времени (только для текущего уровня)                      // Комментарий: таймер\n",
        "    cudaEvent_t start, stop;                                                               // CUDA events\n",
        "    CHECK_CUDA(cudaEventCreate(&start));                                                   // Создаём start\n",
        "    CHECK_CUDA(cudaEventCreate(&stop));                                                    // Создаём stop\n",
        "    CHECK_CUDA(cudaEventRecord(start));                                                    // Старт измерения\n",
        "\n",
        "    // 1) Делаем scan внутри каждого блока + собираем суммы блоков                           // Комментарий: шаг 1\n",
        "    block_scan_inclusive<<<blocks, threads, threads * (int)sizeof(int)>>>(d_in, d_out, n, d_block_sums); // Запуск ядра 1\n",
        "    CHECK_CUDA(cudaGetLastError());                                                        // Проверка запуска ядра\n",
        "\n",
        "    // 2) Если блоков больше 1 — нужно просканировать d_block_sums рекурсивно               // Комментарий: шаг 2\n",
        "    if (blocks > 1)                                                                        // Если больше одного блока\n",
        "    {                                                                                      // Начало if\n",
        "        int* d_block_prefix = nullptr;                                                     // GPU массив prefix sums для блоков (inclusive)\n",
        "        CHECK_CUDA(cudaMalloc(&d_block_prefix, blocks * sizeof(int)));                     // Выделяем память под prefix\n",
        "\n",
        "        // Рекурсивно сканируем массив сумм блоков (он маленький по сравнению с исходным)  // Комментарий: рекурсия\n",
        "        gpu_scan_inclusive_recursive(d_block_sums, d_block_prefix, blocks, threads);       // Вызов этой же функции для block_sums\n",
        "\n",
        "        // 3) Добавляем оффсеты к каждому элементу каждого блока                             // Комментарий: шаг 3\n",
        "        add_block_offsets<<<blocks, threads>>>(d_out, n, d_block_prefix);                   // Запуск ядра 2\n",
        "        CHECK_CUDA(cudaGetLastError());                                                     // Проверка запуска ядра\n",
        "\n",
        "        CHECK_CUDA(cudaFree(d_block_prefix));                                               // Освобождаем d_block_prefix\n",
        "    }                                                                                      // Конец if\n",
        "\n",
        "    CHECK_CUDA(cudaEventRecord(stop));                                                     // Фиксируем stop\n",
        "    CHECK_CUDA(cudaEventSynchronize(stop));                                                // Ждём завершения вычислений этого уровня\n",
        "\n",
        "    float ms = 0.0f;                                                                       // Переменная для времени\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));                                    // Получаем время (мс)\n",
        "\n",
        "    CHECK_CUDA(cudaEventDestroy(start));                                                   // Удаляем event start\n",
        "    CHECK_CUDA(cudaEventDestroy(stop));                                                    // Удаляем event stop\n",
        "\n",
        "    CHECK_CUDA(cudaFree(d_block_sums));                                                    // Освобождаем суммы блоков\n",
        "\n",
        "    return ms;                                                                             // Возвращаем время (для интереса)\n",
        "}                                                                                          // Конец функции\n",
        "\n",
        "// ---- MAIN: ТЕСТ + ПРОВЕРКА КОРРЕКТНОСТИ --- // Заголовок main\n",
        "\n",
        "int main()                                                                                // Точка входа\n",
        "{                                                                                         // Начало main\n",
        "    //  ТЕСТ НА МАЛЕНЬКОМ МАССИВЕ (п.3 задания)               // Комментарий: тест\n",
        "    std::vector<int> test = {1, 2, 3, 4, 5};                                               // Тестовый массив\n",
        "    std::vector<int> cpu_out(test.size());                                                // Результат CPU\n",
        "    std::vector<int> gpu_out(test.size());                                                // Результат GPU\n",
        "\n",
        "    cpu_scan_inclusive(test, cpu_out);                                                    // CPU scan (эталон)\n",
        "\n",
        "    int* d_in = nullptr;                                                                  // Указатель на вход на GPU\n",
        "    int* d_out = nullptr;                                                                 // Указатель на выход на GPU\n",
        "    CHECK_CUDA(cudaMalloc(&d_in, test.size() * sizeof(int)));                             // Память под вход\n",
        "    CHECK_CUDA(cudaMalloc(&d_out, test.size() * sizeof(int)));                            // Память под выход\n",
        "    CHECK_CUDA(cudaMemcpy(d_in, test.data(), test.size() * sizeof(int), cudaMemcpyHostToDevice)); // Копируем вход на GPU\n",
        "\n",
        "    int threads = 256;                                                                    // Размер блока (потоков)\n",
        "    float gpu_ms_test = gpu_scan_inclusive_recursive(d_in, d_out, (int)test.size(), threads);     // GPU scan\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(gpu_out.data(), d_out, test.size() * sizeof(int), cudaMemcpyDeviceToHost)); // Копируем результат на CPU\n",
        "\n",
        "    printf(\"Test input:      \");                                                          // Печать входа\n",
        "    for (size_t i = 0; i < test.size(); ++i) printf(\"%d \", test[i]);                      // Печать элементов\n",
        "    printf(\"\\n\");                                                                         // Перевод строки\n",
        "\n",
        "    printf(\"CPU scan:        \");                                                          // Печать CPU результата\n",
        "    for (size_t i = 0; i < cpu_out.size(); ++i) printf(\"%d \", cpu_out[i]);                // Печать CPU элементов\n",
        "    printf(\"\\n\");                                                                         // Перевод строки\n",
        "\n",
        "    printf(\"GPU scan:        \");                                                          // Печать GPU результата\n",
        "    for (size_t i = 0; i < gpu_out.size(); ++i) printf(\"%d \", gpu_out[i]);                // Печать GPU элементов\n",
        "    printf(\"\\n\");                                                                         // Перевод строки\n",
        "\n",
        "    bool ok = true;                                                                       // Флаг корректности\n",
        "    for (size_t i = 0; i < test.size(); ++i)                                              // Сравниваем результаты\n",
        "    {                                                                                     // Начало цикла\n",
        "        if (cpu_out[i] != gpu_out[i]) ok = false;                                         // Если где-то не совпало — ошибка\n",
        "    }                                                                                     // Конец цикла\n",
        "\n",
        "    printf(\"Test result: %s | GPU level-time: %.3f ms\\n\", ok ? \"OK\" : \"ERROR\", gpu_ms_test); // Итог теста\n",
        "\n",
        "    CHECK_CUDA(cudaFree(d_in));                                                           // Освобождаем d_in\n",
        "    CHECK_CUDA(cudaFree(d_out));                                                          // Освобождаем d_out\n",
        "\n",
        "    if (!ok) return 1;                                                                    // Если тест не прошёл — завершаем\n",
        "\n",
        "    //  ДОПОЛНИТЕЛЬНО: БОЛЬШОЙ ТЕСТ (не обязателен, но полезен) ------ // Комментарий: бенч\n",
        "    int N = 1'000'000;                                                                    // Размер большого массива\n",
        "    std::vector<int> h_in(N);                                                             // Вход на CPU\n",
        "    std::vector<int> h_cpu(N);                                                            // CPU результат\n",
        "    std::vector<int> h_gpu(N);                                                            // GPU результат\n",
        "\n",
        "    std::mt19937 rng(123);                                                                // Генератор\n",
        "    std::uniform_int_distribution<int> dist(0, 9);                                        // Значения 0..9\n",
        "    for (int i = 0; i < N; ++i) h_in[i] = dist(rng);                                      // Заполняем вход\n",
        "\n",
        "    auto c0 = std::chrono::high_resolution_clock::now();                                  // Старт CPU таймера\n",
        "    cpu_scan_inclusive(h_in, h_cpu);                                                      // CPU scan\n",
        "    auto c1 = std::chrono::high_resolution_clock::now();                                  // Стоп CPU таймера\n",
        "    double cpu_ms = std::chrono::duration<double, std::milli>(c1 - c0).count();           // CPU время (мс)\n",
        "\n",
        "    CHECK_CUDA(cudaMalloc(&d_in, N * sizeof(int)));                                       // Память под d_in\n",
        "    CHECK_CUDA(cudaMalloc(&d_out, N * sizeof(int)));                                      // Память под d_out\n",
        "    CHECK_CUDA(cudaMemcpy(d_in, h_in.data(), N * sizeof(int), cudaMemcpyHostToDevice));   // Копируем вход на GPU\n",
        "\n",
        "    float gpu_ms = gpu_scan_inclusive_recursive(d_in, d_out, N, threads);                 // GPU scan\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(h_gpu.data(), d_out, N * sizeof(int), cudaMemcpyDeviceToHost)); // Копируем результат назад\n",
        "\n",
        "    bool ok2 = true;                                                                      // Флаг корректности\n",
        "    for (int i = 0; i < N; ++i)                                                           // Проверяем все элементы\n",
        "    {                                                                                     // Начало цикла\n",
        "        if (h_cpu[i] != h_gpu[i]) { ok2 = false; break; }                                 // Если ошибка — выходим\n",
        "    }                                                                                     // Конец цикла\n",
        "\n",
        "    printf(\"Big test N=%d | CPU=%.3f ms | GPU(level-time)=%.3f ms | %s\\n\",                 // Печать результатов\n",
        "           N, cpu_ms, gpu_ms, ok2 ? \"OK\" : \"ERROR\");                                      // Вывод OK/ERROR\n",
        "\n",
        "    CHECK_CUDA(cudaFree(d_in));                                                           // Освобождаем d_in\n",
        "    CHECK_CUDA(cudaFree(d_out));                                                          // Освобождаем d_out\n",
        "\n",
        "    return ok2 ? 0 : 1;                                                                   // Код возврата\n",
        "}                                                                                         // Конец main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJrd4L_P0aiY",
        "outputId": "ec96a7d3-90de-42e0-d4f3-920c264e0f6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 task2.cu -o task2 \\\n",
        "  -gencode arch=compute_75,code=sm_75\n",
        "!./task2"
      ],
      "metadata": {
        "id": "080M7cJm4onp",
        "outputId": "4c842e58-76a4-499b-8da8-ec00d8c500f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test input:      1 2 3 4 5 \n",
            "CPU scan:        1 3 6 10 15 \n",
            "GPU scan:        1 3 6 10 15 \n",
            "Test result: OK | GPU level-time: 0.126 ms\n",
            "Big test N=1000000 | CPU=0.606 ms | GPU(level-time)=0.239 ms | OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Анализ результатов**\n",
        "\n",
        "По результатам выполнения второго задания установлено, что реализация префиксной суммы на GPU работает корректно, так как значения, полученные на CPU и GPU, полностью совпадают для тестового массива. Это подтверждает правильность работы CUDA-ядра. При малом размере массива время выполнения на GPU не является показательным из-за накладных расходов на запуск ядра. Для большого массива размером 1 000 000 элементов GPU-реализация показала более высокую производительность по сравнению с CPU: время выполнения ядра на GPU составило 0.239 мс против 0.606 мс на CPU. Полученное ускорение объясняется параллельной обработкой данных и использованием разделяемой памяти, что снижает количество обращений к глобальной памяти."
      ],
      "metadata": {
        "id": "i5OnS4PoBm10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 3: Анализ производительности**\n",
        "1. Замерьте время выполнения редукции и сканирования для массивов\n",
        "разного размера.\n",
        "2. Сравните производительность с CPU-реализацией.\n",
        "3. Проведите оптимизацию кода, используя различные типы памяти\n",
        "CUDA"
      ],
      "metadata": {
        "id": "c3LYzJa_0avo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task3.cu\n",
        "#include <cuda_runtime.h>                                                   // Подключаем CUDA Runtime API\n",
        "#include <cstdio>                                                           // Подключаем printf\n",
        "#include <vector>                                                           // Подключаем std::vector\n",
        "#include <random>                                                           // Подключаем генератор случайных чисел\n",
        "#include <chrono>                                                           // Подключаем chrono для времени на CPU\n",
        "#include <fstream>                                                          // Подключаем запись в CSV\n",
        "#include <cstdlib>                                                          // Подключаем std::exit\n",
        "#include <string>                                                           // Подключаем std::string\n",
        "#include <utility>                                                          // Подключаем std::pair\n",
        "\n",
        "static inline void cuda_check(cudaError_t err, const char* file, int line)  // Функция: проверяет ошибки CUDA\n",
        "{                                                                           // Начало функции\n",
        "    if (err != cudaSuccess)                                                 // Если ошибка\n",
        "    {                                                                       // Начало if\n",
        "        printf(\"Ошибка CUDA %s:%d: %s\\n\", file, line, cudaGetErrorString(err)); // Печатаем ошибку\n",
        "        std::exit(1);                                                       // Завершаем программу\n",
        "    }                                                                       // Конец if\n",
        "}                                                                           // Конец функции\n",
        "\n",
        "#define CHECK_CUDA(call) cuda_check((call), __FILE__, __LINE__)             // Макрос удобной проверки\n",
        "\n",
        "//  CPU РЕАЛИЗАЦИИ  // CPU функции для сравнения\n",
        "\n",
        "static long long cpu_reduce_sum(const int* a, int n)                         // CPU: редукция (сумма массива)\n",
        "{                                                                            // Начало функции\n",
        "    long long s = 0;                                                         // Сумма\n",
        "    for (int i = 0; i < n; ++i) s += (long long)a[i];                        // Складываем элементы\n",
        "    return s;                                                                 // Возвращаем сумму\n",
        "}                                                                            // Конец функции\n",
        "\n",
        "static void cpu_scan_inclusive(const int* in, int* out, int n)                // CPU: inclusive scan (префиксная сумма)\n",
        "{                                                                            // Начало функции\n",
        "    long long run = 0;                                                       // Накопитель\n",
        "    for (int i = 0; i < n; ++i)                                              // Цикл по массиву\n",
        "    {                                                                        // Начало цикла\n",
        "        run += (long long)in[i];                                             // Добавляем текущий элемент\n",
        "        out[i] = (int)run;                                                   // Записываем префиксную сумму\n",
        "    }                                                                        // Конец цикла\n",
        "}                                                                            // Конец функции\n",
        "\n",
        "//  GPU: СКАНИРОВАНИЕ  // GPU scan (префиксная сумма)\n",
        "\n",
        "// Ядро 1: scan внутри блока (shared memory) + сохраняем сумму блока\n",
        "__global__ void block_scan_inclusive(const int* in, int* out, int n, int* block_sums) // CUDA-ядро сканирования\n",
        "{                                                                                       // Начало ядра\n",
        "    extern __shared__ unsigned char smem[];                                             // Общий shared буфер в байтах (чтобы не было конфликтов типов)\n",
        "    int* sh = reinterpret_cast<int*>(smem);                                             // Интерпретируем shared как массив int\n",
        "\n",
        "    int tid = threadIdx.x;                                                              // Индекс потока в блоке\n",
        "    int gid = blockIdx.x * blockDim.x + tid;                                            // Глобальный индекс\n",
        "\n",
        "    int x = 0;                                                                          // Значение по умолчанию\n",
        "    if (gid < n) x = in[gid];                                                           // Читаем вход, если в пределах\n",
        "    sh[tid] = x;                                                                        // Пишем в shared\n",
        "    __syncthreads();                                                                    // Синхронизация\n",
        "\n",
        "    // Hillis–Steele inclusive scan в shared\n",
        "    for (int offset = 1; offset < blockDim.x; offset <<= 1)                             // offset = 1,2,4,...\n",
        "    {                                                                                   // Начало цикла\n",
        "        int add = 0;                                                                    // Добавка\n",
        "        if (tid >= offset) add = sh[tid - offset];                                      // Читаем слева\n",
        "        __syncthreads();                                                                // Синхронизация чтения\n",
        "        sh[tid] += add;                                                                 // Обновляем\n",
        "        __syncthreads();                                                                // Синхронизация записи\n",
        "    }                                                                                   // Конец цикла\n",
        "\n",
        "    if (gid < n) out[gid] = sh[tid];                                                    // Записываем результат в global\n",
        "\n",
        "    // Сумма блока = последний валидный элемент в этом блоке\n",
        "    int block_start = blockIdx.x * blockDim.x;                                          // Начало блока\n",
        "    int valid = n - block_start;                                                        // Кол-во валидных элементов\n",
        "    if (valid > blockDim.x) valid = blockDim.x;                                         // Ограничиваем размером блока\n",
        "    if (valid > 0 && tid == valid - 1)                                                  // Последний валидный поток\n",
        "    {                                                                                   // Начало if\n",
        "        block_sums[blockIdx.x] = sh[tid];                                               // Пишем сумму блока\n",
        "    }                                                                                   // Конец if\n",
        "}                                                                                       // Конец ядра\n",
        "\n",
        "// Ядро 2: добавляет оффсеты блоков (суммы предыдущих блоков) к каждому элементу\n",
        "__global__ void add_block_offsets(int* out, int n, const int* block_prefix)              // CUDA-ядро добавления оффсетов\n",
        "{                                                                                       // Начало ядра\n",
        "    int tid = threadIdx.x;                                                              // Индекс потока\n",
        "    int gid = blockIdx.x * blockDim.x + tid;                                            // Глобальный индекс\n",
        "    if (gid >= n) return;                                                               // Проверка границ\n",
        "\n",
        "    int b = blockIdx.x;                                                                 // Номер блока\n",
        "    int offset = 0;                                                                     // Оффсет по умолчанию\n",
        "    if (b > 0) offset = block_prefix[b - 1];                                            // Сумма всех предыдущих блоков\n",
        "    out[gid] += offset;                                                                 // Добавляем оффсет\n",
        "}                                                                                       // Конец ядра\n",
        "\n",
        "// Рекурсивный scan: сканирует block_sums пока не останется 1 блок\n",
        "static float gpu_scan_inclusive_recursive(const int* d_in, int* d_out, int n, int threads) // GPU scan (kernel-time на текущем уровне)\n",
        "{                                                                                          // Начало функции\n",
        "    int blocks = (n + threads - 1) / threads;                                              // Количество блоков\n",
        "\n",
        "    int* d_block_sums = nullptr;                                                           // Суммы блоков\n",
        "    CHECK_CUDA(cudaMalloc(&d_block_sums, blocks * sizeof(int)));                           // Выделяем память\n",
        "\n",
        "    cudaEvent_t start, stop;                                                               // CUDA события\n",
        "    CHECK_CUDA(cudaEventCreate(&start));                                                   // Создаём start\n",
        "    CHECK_CUDA(cudaEventCreate(&stop));                                                    // Создаём stop\n",
        "    CHECK_CUDA(cudaEventRecord(start));                                                    // Старт измерения\n",
        "\n",
        "    // 1) Scan в каждом блоке + суммы блоков\n",
        "    block_scan_inclusive<<<blocks, threads, threads * (int)sizeof(int)>>>(d_in, d_out, n, d_block_sums); // shared = threads*sizeof(int)\n",
        "    CHECK_CUDA(cudaGetLastError());                                                        // Проверяем запуск\n",
        "\n",
        "    // 2) Если блоков больше 1 — сканируем суммы блоков\n",
        "    if (blocks > 1)                                                                        // Если нужно\n",
        "    {                                                                                      // Начало if\n",
        "        int* d_block_prefix = nullptr;                                                     // Prefix sums для блоков\n",
        "        CHECK_CUDA(cudaMalloc(&d_block_prefix, blocks * sizeof(int)));                     // Выделяем память\n",
        "\n",
        "        gpu_scan_inclusive_recursive(d_block_sums, d_block_prefix, blocks, threads);       // Рекурсивный scan block_sums\n",
        "\n",
        "        add_block_offsets<<<blocks, threads>>>(d_out, n, d_block_prefix);                  // Добавляем оффсеты\n",
        "        CHECK_CUDA(cudaGetLastError());                                                    // Проверяем запуск\n",
        "\n",
        "        CHECK_CUDA(cudaFree(d_block_prefix));                                              // Освобождаем\n",
        "    }                                                                                      // Конец if\n",
        "\n",
        "    CHECK_CUDA(cudaEventRecord(stop));                                                     // Стоп измерения\n",
        "    CHECK_CUDA(cudaEventSynchronize(stop));                                                // Ждём завершения\n",
        "\n",
        "    float ms = 0.0f;                                                                       // Время\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));                                    // Kernel time (мс)\n",
        "\n",
        "    CHECK_CUDA(cudaEventDestroy(start));                                                   // Удаляем события\n",
        "    CHECK_CUDA(cudaEventDestroy(stop));                                                    // Удаляем события\n",
        "    CHECK_CUDA(cudaFree(d_block_sums));                                                    // Освобождаем block_sums\n",
        "\n",
        "    return ms;                                                                             // Возвращаем время\n",
        "}                                                                                          // Конец функции\n",
        "\n",
        "//  GPU: РЕДУКЦИЯ (СУММА)  // GPU reduction (сумма массива)\n",
        "\n",
        "// Ядро редукции: каждый блок считает частичную сумму в shared памяти\n",
        "__global__ void reduce_sum_block(const int* in, long long* block_out, int n)               // CUDA-ядро редукции\n",
        "{                                                                                           // Начало ядра\n",
        "    extern __shared__ unsigned char smem[];                                                 // Общий shared буфер в байтах\n",
        "    long long* sh = reinterpret_cast<long long*>(smem);                                     // Интерпретируем shared как long long[]\n",
        "\n",
        "    int tid = threadIdx.x;                                                                  // Индекс потока\n",
        "    int gid = blockIdx.x * blockDim.x + tid;                                                // Глобальный индекс\n",
        "\n",
        "    long long x = 0;                                                                        // Значение по умолчанию\n",
        "    if (gid < n) x = (long long)in[gid];                                                    // Читаем вход\n",
        "    sh[tid] = x;                                                                            // Пишем в shared\n",
        "    __syncthreads();                                                                        // Синхронизация\n",
        "\n",
        "    // Деревянная редукция в shared\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)                             // stride: 128,64,32...\n",
        "    {                                                                                       // Начало цикла\n",
        "        if (tid < stride) sh[tid] += sh[tid + stride];                                      // Складываем пары\n",
        "        __syncthreads();                                                                    // Синхронизация\n",
        "    }                                                                                       // Конец цикла\n",
        "\n",
        "    if (tid == 0) block_out[blockIdx.x] = sh[0];                                            // Поток 0 пишет сумму блока\n",
        "}                                                                                           // Конец ядра\n",
        "\n",
        "// GPU reduction: возвращает (сумма, kernel_ms). Итоговую сумму собираем на CPU (просто для лабы)\n",
        "static std::pair<long long, float> gpu_reduce_sum(const int* d_in, int n, int threads)     // GPU редукция\n",
        "{                                                                                           // Начало функции\n",
        "    int blocks = (n + threads - 1) / threads;                                               // Кол-во блоков\n",
        "\n",
        "    long long* d_part = nullptr;                                                            // Частичные суммы блоков на GPU\n",
        "    CHECK_CUDA(cudaMalloc(&d_part, blocks * sizeof(long long)));                            // Выделяем память\n",
        "\n",
        "    cudaEvent_t start, stop;                                                                // CUDA события\n",
        "    CHECK_CUDA(cudaEventCreate(&start));                                                    // Создаём start\n",
        "    CHECK_CUDA(cudaEventCreate(&stop));                                                     // Создаём stop\n",
        "    CHECK_CUDA(cudaEventRecord(start));                                                     // Старт измерения\n",
        "\n",
        "    reduce_sum_block<<<blocks, threads, threads * (int)sizeof(long long)>>>(d_in, d_part, n); // shared = threads*sizeof(long long)\n",
        "    CHECK_CUDA(cudaGetLastError());                                                         // Проверяем запуск\n",
        "\n",
        "    CHECK_CUDA(cudaEventRecord(stop));                                                      // Стоп\n",
        "    CHECK_CUDA(cudaEventSynchronize(stop));                                                 // Ждём завершения\n",
        "\n",
        "    float ms = 0.0f;                                                                        // Время\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));                                     // Kernel time (мс)\n",
        "\n",
        "    std::vector<long long> h_part(blocks);                                                  // Буфер на CPU\n",
        "    CHECK_CUDA(cudaMemcpy(h_part.data(), d_part, blocks * sizeof(long long), cudaMemcpyDeviceToHost)); // D2H частичных сумм\n",
        "\n",
        "    long long sum = 0;                                                                      // Итоговая сумма\n",
        "    for (int i = 0; i < blocks; ++i) sum += h_part[i];                                      // Складываем частичные суммы на CPU\n",
        "\n",
        "    CHECK_CUDA(cudaEventDestroy(start));                                                    // Удаляем events\n",
        "    CHECK_CUDA(cudaEventDestroy(stop));                                                     // Удаляем events\n",
        "    CHECK_CUDA(cudaFree(d_part));                                                           // Освобождаем d_part\n",
        "\n",
        "    return {sum, ms};                                                                       // Возвращаем (сумма, время)\n",
        "}                                                                                           // Конец функции\n",
        "\n",
        "//  TOTAL ВРЕМЯ (H2D + kernel + D2H)  // Для сравнения \"в реальности\"\n",
        "\n",
        "// TOTAL время scan (включая копирования)\n",
        "static float gpu_scan_total_time_ms(const int* h_in, int* h_out, int n, int threads)        // TOTAL scan time\n",
        "{\n",
        "    int *d_in = nullptr, *d_out = nullptr;                                                  // Указатели на GPU\n",
        "    CHECK_CUDA(cudaMalloc(&d_in, n * sizeof(int)));                                         // Выделяем d_in\n",
        "    CHECK_CUDA(cudaMalloc(&d_out, n * sizeof(int)));                                        // Выделяем d_out\n",
        "\n",
        "    cudaEvent_t start, stop;                                                                // CUDA события\n",
        "    CHECK_CUDA(cudaEventCreate(&start));                                                    // Создаём start\n",
        "    CHECK_CUDA(cudaEventCreate(&stop));                                                     // Создаём stop\n",
        "    CHECK_CUDA(cudaEventRecord(start));                                                     // Старт времени\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(d_in, h_in, n * sizeof(int), cudaMemcpyHostToDevice));            // H2D\n",
        "    gpu_scan_inclusive_recursive(d_in, d_out, n, threads);                                  // Kernel scan\n",
        "    CHECK_CUDA(cudaMemcpy(h_out, d_out, n * sizeof(int), cudaMemcpyDeviceToHost));          // D2H\n",
        "\n",
        "    CHECK_CUDA(cudaEventRecord(stop));                                                      // Стоп времени\n",
        "    CHECK_CUDA(cudaEventSynchronize(stop));                                                 // Ждём завершения\n",
        "\n",
        "    float ms = 0.0f;                                                                        // Время\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));                                     // TOTAL (мс)\n",
        "\n",
        "    CHECK_CUDA(cudaEventDestroy(start));                                                    // Удаляем events\n",
        "    CHECK_CUDA(cudaEventDestroy(stop));                                                     // Удаляем events\n",
        "    CHECK_CUDA(cudaFree(d_in));                                                             // Освобождаем d_in\n",
        "    CHECK_CUDA(cudaFree(d_out));                                                            // Освобождаем d_out\n",
        "\n",
        "    return ms;                                                                              // Возвращаем время\n",
        "}\n",
        "\n",
        "// TOTAL время reduce (включая H2D и D2H частичных сумм)\n",
        "static float gpu_reduce_total_time_ms(const int* h_in, long long* out_sum, int n, int threads) // TOTAL reduce time\n",
        "{\n",
        "    int* d_in = nullptr;                                                                    // Вход на GPU\n",
        "    CHECK_CUDA(cudaMalloc(&d_in, n * sizeof(int)));                                         // Выделяем память\n",
        "\n",
        "    cudaEvent_t start, stop;                                                                // CUDA события\n",
        "    CHECK_CUDA(cudaEventCreate(&start));                                                    // Создаём start\n",
        "    CHECK_CUDA(cudaEventCreate(&stop));                                                     // Создаём stop\n",
        "    CHECK_CUDA(cudaEventRecord(start));                                                     // Старт времени\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(d_in, h_in, n * sizeof(int), cudaMemcpyHostToDevice));            // H2D\n",
        "    auto info = gpu_reduce_sum(d_in, n, threads);                                           // Kernel + D2H частичных сумм внутри\n",
        "    *out_sum = info.first;                                                                  // Сохраняем сумму\n",
        "\n",
        "    CHECK_CUDA(cudaEventRecord(stop));                                                      // Стоп\n",
        "    CHECK_CUDA(cudaEventSynchronize(stop));                                                 // Ждём\n",
        "\n",
        "    float ms = 0.0f;                                                                        // Время\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&ms, start, stop));                                     // TOTAL (мс)\n",
        "\n",
        "    CHECK_CUDA(cudaEventDestroy(start));                                                    // Удаляем events\n",
        "    CHECK_CUDA(cudaEventDestroy(stop));                                                     // Удаляем events\n",
        "    CHECK_CUDA(cudaFree(d_in));                                                             // Освобождаем d_in\n",
        "\n",
        "    return ms;                                                                              // Возвращаем время\n",
        "}\n",
        "\n",
        "//  MAIN: БЕНЧМАРК\n",
        "\n",
        "int main()\n",
        "{\n",
        "    std::vector<int> sizes = {                                                              // Размеры массивов для тестов\n",
        "        10'000, 50'000, 100'000, 200'000, 500'000,\n",
        "        1'000'000, 2'000'000, 5'000'000, 10'000'000\n",
        "    };\n",
        "\n",
        "    int threads = 256;                                                                      // Потоки в блоке (можно менять 128/256/512)\n",
        "\n",
        "    std::ofstream csv(\"perf_results.csv\");                                                  // Открываем CSV\n",
        "    csv << \"режим,N,CPU_scan_мс,CPU_reduce_мс,GPU_scan_kernel_мс,GPU_reduce_kernel_мс,GPU_scan_total_мс,GPU_reduce_total_мс,ok\\n\";\n",
        "\n",
        "    std::mt19937 rng(123);                                                                  // RNG\n",
        "    std::uniform_int_distribution<int> dist(0, 9);                                          // Значения 0..9\n",
        "\n",
        "    // Два режима памяти на CPU: обычная и pinned (закреплённая)\n",
        "    for (int mode = 0; mode < 2; ++mode)\n",
        "    {\n",
        "        std::string mode_name = (mode == 0) ? \"обычная_память\" : \"pinned_память\";           // Название режима\n",
        "        printf(\"\\n=== РЕЖИМ: %s ===\\n\", mode_name.c_str());                                 // Печатаем режим\n",
        "\n",
        "        for (int N : sizes)\n",
        "        {\n",
        "            //  Выделяем память на CPU\n",
        "            int* h_in = nullptr;                                                            // Вход\n",
        "            int* h_scan_out = nullptr;                                                      // Выход scan (для total времени)\n",
        "\n",
        "            if (mode == 0)\n",
        "            {\n",
        "                h_in = new int[N];                                                          // Обычная память\n",
        "                h_scan_out = new int[N];                                                    // Обычная память\n",
        "            }\n",
        "            else\n",
        "            {\n",
        "                CHECK_CUDA(cudaHostAlloc(&h_in, N * sizeof(int), cudaHostAllocDefault));    // Pinned память\n",
        "                CHECK_CUDA(cudaHostAlloc(&h_scan_out, N * sizeof(int), cudaHostAllocDefault)); // Pinned память\n",
        "            }\n",
        "\n",
        "            for (int i = 0; i < N; ++i) h_in[i] = dist(rng);                                // Заполняем вход\n",
        "\n",
        "            // CPU: считаем эталонные результаты\n",
        "            std::vector<int> cpu_scan(N);                                                   // CPU scan результат\n",
        "            long long cpu_sum = 0;                                                          // CPU sum результат\n",
        "\n",
        "            auto c0 = std::chrono::high_resolution_clock::now();                            // Старт CPU scan\n",
        "            cpu_scan_inclusive(h_in, cpu_scan.data(), N);                                   // CPU scan\n",
        "            auto c1 = std::chrono::high_resolution_clock::now();                            // Стоп CPU scan\n",
        "            double cpu_scan_ms = std::chrono::duration<double, std::milli>(c1 - c0).count();// CPU scan (мс)\n",
        "\n",
        "            auto r0 = std::chrono::high_resolution_clock::now();                            // Старт CPU reduce\n",
        "            cpu_sum = cpu_reduce_sum(h_in, N);                                              // CPU reduce\n",
        "            auto r1 = std::chrono::high_resolution_clock::now();                            // Стоп CPU reduce\n",
        "            double cpu_reduce_ms = std::chrono::duration<double, std::milli>(r1 - r0).count();// CPU reduce (мс)\n",
        "\n",
        "            //  GPU kernel-only: данные на GPU\n",
        "            int* d_in = nullptr;                                                            // d_in\n",
        "            int* d_scan_out = nullptr;                                                      // d_out scan\n",
        "            CHECK_CUDA(cudaMalloc(&d_in, N * sizeof(int)));                                 // alloc\n",
        "            CHECK_CUDA(cudaMalloc(&d_scan_out, N * sizeof(int)));                           // alloc\n",
        "            CHECK_CUDA(cudaMemcpy(d_in, h_in, N * sizeof(int), cudaMemcpyHostToDevice));    // H2D\n",
        "\n",
        "            float gpu_scan_kernel_ms = gpu_scan_inclusive_recursive(d_in, d_scan_out, N, threads); // scan kernel time\n",
        "            auto red_info = gpu_reduce_sum(d_in, N, threads);                                // reduce: (sum, kernel time)\n",
        "            long long gpu_sum_kernel = red_info.first;                                       // GPU сумма\n",
        "            float gpu_reduce_kernel_ms = red_info.second;                                    // GPU reduce kernel time\n",
        "\n",
        "            bool ok = (gpu_sum_kernel == cpu_sum);                                           // Проверка суммы\n",
        "\n",
        "            // Проверка scan (не сравниваем весь массив ради скорости — 3 точки)\n",
        "            std::vector<int> tmp_scan(N);                                                    // Временный буфер\n",
        "            CHECK_CUDA(cudaMemcpy(tmp_scan.data(), d_scan_out, N * sizeof(int), cudaMemcpyDeviceToHost)); // D2H\n",
        "            if (tmp_scan[0] != cpu_scan[0]) ok = false;                                      // первый\n",
        "            if (tmp_scan[N / 2] != cpu_scan[N / 2]) ok = false;                              // середина\n",
        "            if (tmp_scan[N - 1] != cpu_scan[N - 1]) ok = false;                              // последний\n",
        "\n",
        "            CHECK_CUDA(cudaFree(d_in));                                                      // free\n",
        "            CHECK_CUDA(cudaFree(d_scan_out));                                                // free\n",
        "\n",
        "            //  GPU total: H2D + kernel + D2H\n",
        "            long long gpu_sum_total = 0;                                                     // GPU сумма total\n",
        "            float gpu_reduce_total_ms = gpu_reduce_total_time_ms(h_in, &gpu_sum_total, N, threads); // total reduce\n",
        "            if (gpu_sum_total != cpu_sum) ok = false;                                        // проверка total reduce\n",
        "\n",
        "            float gpu_scan_total_ms = gpu_scan_total_time_ms(h_in, h_scan_out, N, threads);  // total scan\n",
        "            if (h_scan_out[0] != cpu_scan[0]) ok = false;                                    // проверка total scan\n",
        "            if (h_scan_out[N - 1] != cpu_scan[N - 1]) ok = false;                            // проверка total scan\n",
        "\n",
        "            // Вывод\n",
        "            printf(\"N=%d | CPU scan=%.3f мс | CPU reduce=%.3f мс | GPU scan kernel=%.3f мс | GPU reduce kernel=%.3f мс | GPU scan total=%.3f мс | GPU reduce total=%.3f мс | %s\\n\",\n",
        "                   N,\n",
        "                   (float)cpu_scan_ms,\n",
        "                   (float)cpu_reduce_ms,\n",
        "                   gpu_scan_kernel_ms,\n",
        "                   gpu_reduce_kernel_ms,\n",
        "                   gpu_scan_total_ms,\n",
        "                   gpu_reduce_total_ms,\n",
        "                   ok ? \"OK\" : \"ОШИБКА\");\n",
        "\n",
        "            // CSV\n",
        "            csv << mode_name << \",\" << N << \",\"\n",
        "                << cpu_scan_ms << \",\" << cpu_reduce_ms << \",\"\n",
        "                << gpu_scan_kernel_ms << \",\" << gpu_reduce_kernel_ms << \",\"\n",
        "                << gpu_scan_total_ms << \",\" << gpu_reduce_total_ms << \",\"\n",
        "                << (ok ? 1 : 0) << \"\\n\";\n",
        "\n",
        "            // Освобождаем память CPU\n",
        "            if (mode == 0)\n",
        "            {\n",
        "                delete[] h_in;                                                               // free pageable\n",
        "                delete[] h_scan_out;                                                         // free pageable\n",
        "            }\n",
        "            else\n",
        "            {\n",
        "                CHECK_CUDA(cudaFreeHost(h_in));                                              // free pinned\n",
        "                CHECK_CUDA(cudaFreeHost(h_scan_out));                                        // free pinned\n",
        "            }\n",
        "\n",
        "            if (!ok)                                                                         // Если ошибка — выходим\n",
        "            {\n",
        "                printf(\"Обнаружена ошибка при N=%d (режим=%s)\\n\", N, mode_name.c_str());\n",
        "                csv.close();\n",
        "                return 1;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    csv.close();\n",
        "    printf(\"\\nСохранено: perf_results.csv\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9RLO-Ol--8k",
        "outputId": "8c840580-0d7d-4f57-f44b-95ab9d594de3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 task3.cu -o task3 -gencode arch=compute_75,code=sm_75\n",
        "!./task3\n",
        "!head perf_results.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt5NBk9t_ZZR",
        "outputId": "a35e68ac-a092-4b61-e65f-28f377a78898"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== РЕЖИМ: обычная_память ===\n",
            "N=10000 | CPU scan=0.008 мс | CPU reduce=0.002 мс | GPU scan kernel=0.240 мс | GPU reduce kernel=0.023 мс | GPU scan total=0.157 мс | GPU reduce total=0.079 мс | OK\n",
            "N=50000 | CPU scan=0.047 мс | CPU reduce=0.013 мс | GPU scan kernel=0.060 мс | GPU reduce kernel=0.012 мс | GPU scan total=0.287 мс | GPU reduce total=0.113 мс | OK\n",
            "N=100000 | CPU scan=0.063 мс | CPU reduce=0.020 мс | GPU scan kernel=0.089 мс | GPU reduce kernel=0.017 мс | GPU scan total=0.330 мс | GPU reduce total=0.167 мс | OK\n",
            "N=200000 | CPU scan=0.153 мс | CPU reduce=0.042 мс | GPU scan kernel=0.105 мс | GPU reduce kernel=0.028 мс | GPU scan total=0.569 мс | GPU reduce total=0.320 мс | OK\n",
            "N=500000 | CPU scan=0.335 мс | CPU reduce=0.115 мс | GPU scan kernel=0.149 мс | GPU reduce kernel=0.057 мс | GPU scan total=1.446 мс | GPU reduce total=0.580 мс | OK\n",
            "N=1000000 | CPU scan=0.654 мс | CPU reduce=0.220 мс | GPU scan kernel=0.221 мс | GPU reduce kernel=0.109 мс | GPU scan total=3.878 мс | GPU reduce total=1.099 мс | OK\n",
            "N=2000000 | CPU scan=1.357 мс | CPU reduce=0.512 мс | GPU scan kernel=0.365 мс | GPU reduce kernel=0.209 мс | GPU scan total=7.609 мс | GPU reduce total=1.982 мс | OK\n",
            "N=5000000 | CPU scan=3.758 мс | CPU reduce=1.955 мс | GPU scan kernel=0.808 мс | GPU reduce kernel=0.510 мс | GPU scan total=19.310 мс | GPU reduce total=5.176 мс | OK\n",
            "N=10000000 | CPU scan=7.912 мс | CPU reduce=3.963 мс | GPU scan kernel=1.509 мс | GPU reduce kernel=1.007 мс | GPU scan total=47.968 мс | GPU reduce total=12.988 мс | OK\n",
            "\n",
            "=== РЕЖИМ: pinned_память ===\n",
            "N=10000 | CPU scan=0.010 мс | CPU reduce=0.019 мс | GPU scan kernel=0.074 мс | GPU reduce kernel=0.010 мс | GPU scan total=0.139 мс | GPU reduce total=0.075 мс | OK\n",
            "N=50000 | CPU scan=0.056 мс | CPU reduce=0.018 мс | GPU scan kernel=0.066 мс | GPU reduce kernel=0.014 мс | GPU scan total=0.145 мс | GPU reduce total=0.094 мс | OK\n",
            "N=100000 | CPU scan=0.071 мс | CPU reduce=0.026 мс | GPU scan kernel=0.117 мс | GPU reduce kernel=0.018 мс | GPU scan total=0.232 мс | GPU reduce total=0.115 мс | OK\n",
            "N=200000 | CPU scan=0.193 мс | CPU reduce=0.064 мс | GPU scan kernel=0.106 мс | GPU reduce kernel=0.026 мс | GPU scan total=0.317 мс | GPU reduce total=0.164 мс | OK\n",
            "N=500000 | CPU scan=0.536 мс | CPU reduce=0.184 мс | GPU scan kernel=0.172 мс | GPU reduce kernel=0.058 мс | GPU scan total=0.578 мс | GPU reduce total=0.321 мс | OK\n",
            "N=1000000 | CPU scan=1.151 мс | CPU reduce=0.410 мс | GPU scan kernel=0.258 мс | GPU reduce kernel=0.115 мс | GPU scan total=1.159 мс | GPU reduce total=0.765 мс | OK\n",
            "N=2000000 | CPU scan=2.395 мс | CPU reduce=0.952 мс | GPU scan kernel=0.384 мс | GPU reduce kernel=0.212 мс | GPU scan total=2.001 мс | GPU reduce total=1.333 мс | OK\n",
            "N=5000000 | CPU scan=6.651 мс | CPU reduce=2.857 мс | GPU scan kernel=0.818 мс | GPU reduce kernel=0.511 мс | GPU scan total=6.059 мс | GPU reduce total=3.380 мс | OK\n",
            "N=10000000 | CPU scan=12.672 мс | CPU reduce=5.610 мс | GPU scan kernel=1.534 мс | GPU reduce kernel=1.008 мс | GPU scan total=10.093 мс | GPU reduce total=7.407 мс | OK\n",
            "\n",
            "Сохранено: perf_results.csv\n",
            "режим,N,CPU_scan_мс,CPU_reduce_мс,GPU_scan_kernel_мс,GPU_reduce_kernel_мс,GPU_scan_total_мс,GPU_reduce_total_мс,ok\n",
            "обычная_память,10000,0.007927,0.002098,0.240032,0.022752,0.157248,0.079136,1\n",
            "обычная_память,50000,0.046546,0.012577,0.059712,0.012416,0.287296,0.11328,1\n",
            "обычная_память,100000,0.063344,0.019879,0.088832,0.016672,0.33024,0.167296,1\n",
            "обычная_память,200000,0.153195,0.042173,0.105472,0.02752,0.568512,0.320032,1\n",
            "обычная_память,500000,0.334939,0.115498,0.148992,0.057184,1.44643,0.579808,1\n",
            "обычная_память,1000000,0.653996,0.220375,0.220896,0.109408,3.87766,1.0993,1\n",
            "обычная_память,2000000,1.35699,0.512232,0.364928,0.209184,7.60874,1.98202,1\n",
            "обычная_память,5000000,3.758,1.95481,0.807776,0.509952,19.3101,5.17552,1\n",
            "обычная_память,10000000,7.91154,3.96278,1.50915,1.0073,47.9676,12.9879,1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Анализ результатов**\n",
        "\n",
        "По результатам, что для небольших массивов CPU работает быстрее GPU, так как накладные расходы на копирование данных и запуск CUDA-ядер превышают выигрыш от параллелизма. При этом kernel-время на GPU уже на малых размерах меньше или сопоставимо с CPU, что говорит о высокой эффективности самих CUDA-ядер сканирования и редукции. С ростом размера массива GPU-kernel становится значительно быстрее CPU, особенно для операций scan и reduce, однако при использовании обычной памяти общее (total) время на GPU резко увеличивается из-за затрат на копирование данных между хостом и устройством. Использование pinned-памяти заметно снижает total-время, особенно на больших размерах, и позволяет GPU-реализации приблизиться к CPU или превзойти его даже с учётом копирований. Во всех экспериментах результаты GPU и CPU совпадают, что подтверждает корректность реализации, а различия во времени наглядно показывают влияние типа памяти и накладных расходов на реальную производительность CUDA-программ."
      ],
      "metadata": {
        "id": "oQeNR54aCNiA"
      }
    }
  ]
}