# Состав проекта:



## Задача 1. Введение в гетерогенную параллелизацию

**Гетерогенная параллелизация** — это подход к организации вычислений, при котором в рамках одной задачи одновременно используются различные типы вычислительных устройств, прежде всего центральный процессор (CPU) и графический процессор (GPU). Каждый из этих процессоров выполняет ту часть вычислений, для которой он наиболее эффективен, что позволяет существенно повысить общую производительность системы.

Различия между параллельными вычислениями на CPU и GPU

**CPU** - предназначен для выполнения широкого спектра задач и оптимизирован для сложной логики, ветвлений и последовательных операций. Он содержит небольшое количество мощных ядер и хорошо справляется с управлением программным потоком, обработкой исключений и задачами, требующими высокой гибкости.

**GPU** - ориентирован на массово-параллельные вычисления. Он содержит тысячи простых ядер, которые выполняют одну и ту же операцию над большим объёмом данных. GPU особенно эффективен для задач с одинаковыми вычислениями над элементами массивов, матриц и потоков данных, где минимальны условные переходы и зависимости.

### Преимущества гетерогенной параллелизации

Основным преимуществом гетерогенной параллелизации является оптимальное использование ресурсов системы. CPU и GPU дополняют друг друга: CPU управляет логикой программы и последовательными этапами, а GPU обрабатывает вычислительно интенсивные параллельные участки.
Это позволяет:

* значительно сократить время выполнения задач;

* повысить пропускную способность вычислений;

* эффективно обрабатывать большие объёмы данных;

* снизить энергозатраты по сравнению с использованием только CPU.

### Примеры реальных приложений

Гетерогенная параллелизация широко используется в современных прикладных системах. Примерами являются:

* машинное обучение и нейронные сети, где GPU ускоряет обучение и обработку данных;

* научные и инженерные расчёты (моделирование физических процессов, численные методы);

* игры и графические приложения, где GPU отвечает за визуализацию, а CPU — за игровую логику.

## Ответы на контрольные вопросы:

## 1. Что понимается под гетерогенной параллелизацией?

Гетерогенная параллелизация — это подход, при котором вычисления распределяются между различными типами вычислительных устройств, такими как CPU и GPU. При этом каждая часть задачи выполняется на том устройстве, которое наиболее эффективно справляется с данным типом вычислений, что позволяет повысить общую производительность системы.

## 2. В чём принципиальные различия архитектур CPU и GPU?

CPU ориентирован на выполнение сложных последовательных задач и имеет небольшое количество мощных ядер с развитой логикой управления и кэшированием.
GPU содержит тысячи более простых ядер и предназначен для массовых параллельных вычислений, где одна и та же операция выполняется над большим количеством данных одновременно.

## 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?

GPU лучше всего подходит для задач с высокой степенью параллелизма, таких как обработка изображений, векторные и матричные вычисления, сортировка больших массивов и машинное обучение.
CPU эффективнее справляется с задачами, содержащими сложную логику, ветвления, последовательные зависимости и управление потоками выполнения.

## 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

Не все алгоритмы имеют достаточный уровень независимых операций. Если между шагами алгоритма существуют сильные зависимости по данным или частая необходимость синхронизации, то параллельное выполнение может привести к большим накладным расходам и не дать прироста производительности.

## 5. В чём заключается основная идея алгоритма сортировки слиянием?

Основная идея сортировки слиянием заключается в рекурсивном разбиении массива на более мелкие части, сортировке этих частей и последующем слиянии отсортированных подмассивов в один упорядоченный массив. Алгоритм основан на принципе «разделяй и властвуй».

## 6. Какие сложности возникают при реализации сортировки слиянием на GPU?

Сложности связаны с необходимостью эффективного параллельного слияния подмассивов, синхронизации потоков и управлением памятью. Кроме того, операции слияния часто требуют нерегулярного доступа к памяти, что снижает эффективность использования GPU.

## 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

Размер блоков и сетки определяет, насколько эффективно будут использоваться вычислительные ресурсы GPU. Неправильный выбор может привести к недостаточной загрузке ядер или превышению доступных ресурсов. Оптимальные параметры позволяют скрывать задержки доступа к памяти и повышают общую производительность вычислений.

## 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?

Гетерогенный подход позволяет использовать сильные стороны каждого устройства: CPU — для управления, логики и последовательных частей алгоритма, а GPU — для массовых параллельных вычислений. Такое распределение нагрузки снижает общее время выполнения задачи и повышает эффективность вычислительной системы.
