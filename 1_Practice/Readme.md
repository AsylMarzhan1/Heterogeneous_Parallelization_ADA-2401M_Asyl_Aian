В данном практисе выполнили 3 задачу и ответили на вопросы:

## 1. В чём основные отличия между массивами и динамическими структурами данных?

Массивы имеют фиксированный размер и занимают непрерывный участок памяти, что обеспечивает быстрый доступ по индексу.
Динамические структуры данных (списки, стеки, очереди) создаются во время выполнения программы, могут изменять размер и используют указатели для связи элементов.

## 2. Что такое указатель, и как он используется в языке C++?

Указатель — это переменная, которая хранит адрес другой переменной в памяти.
В C++ указатели используются для работы с динамической памятью, передачи данных в функции без копирования и реализации динамических структур данных.

## 3. Объясните принцип работы стека и очереди.

Стек работает по принципу LIFO (Last In, First Out) — последний добавленный элемент извлекается первым.
Очередь работает по принципу FIFO (First In, First Out) — первый добавленный элемент извлекается первым.

## 4. Каковы преимущества и недостатки односвязных списков по сравнению с массивами?

Преимущества:

* динамический размер;

* быстрое добавление и удаление элементов.

Недостатки:

* отсутствие прямого доступа по индексу;

* дополнительная память под указатели;

* более низкая производительность из-за плохой кэш-локальности.

## 5. Как правильно освобождать память в языке C++ после работы с динамическими структурами?

Для одиночных объектов используется delete, для массивов — delete[].
При работе с динамическими структурами необходимо последовательно освобождать память всех элементов и корректно обнулять указатели.

## 6. Почему важно понимать работу с указателями и динамической памятью для параллельного программирования?

При параллельном программировании несколько потоков могут обращаться к одной и той же памяти.
Неправильная работа с указателями может привести к гонкам данных, ошибкам синхронизации и аварийному завершению программы.

## 7. Как использовать reduction в OpenMP для нахождения суммы, минимума или максимума в массиве?

Директива reduction позволяет каждому потоку работать с локальной копией переменной и автоматически объединять результаты:

#pragma omp parallel for reduction(+:sum)

for (int i = 0; i < N; i++) {

    sum += arr[i];}

Аналогично используются операции min и max.

## 8. Как влияет параллельное программирование на производительность при работе с большими массивами?

Параллельное программирование позволяет ускорить обработку больших массивов за счёт распределения вычислений между потоками.
Однако при малых объёмах данных или высокой синхронизации накладные расходы могут снизить производительность.
