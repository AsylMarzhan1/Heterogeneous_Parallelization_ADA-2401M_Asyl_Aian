**Ответы на контрольные вопросы:**

1. Чем отличаются типы памяти в CUDA и в каких случаях их использовать?

Типы памяти в CUDA отличаются скоростью работы, объёмом и тем, каким потокам они доступны. 

Самые быстрые — регистры, они используются для локальных вычислений внутри одного потока. 

Глобальная память самая большая, но медленная, поэтому в ней обычно хранят входные и выходные данные. 

Разделяемая память находится внутри мультипроцессора и общая для потоков одного блока, за счёт чего она работает быстрее глобальной и используется как временное хранилище. 

Константная и текстурная память предназначены в основном для чтения и применяются в ситуациях, когда данные либо одинаковы для всех потоков, либо читаются нерегулярно.

2. Как использование разделяемой памяти влияет на производительность?
Разделяемая память ускоряет работу программы, так как уменьшает количество обращений к глобальной памяти. Данные загружаются в неё один раз и затем быстро используются потоками блока. 

Это особенно эффективно в алгоритмах редукции, сортировки и обработке массивов, но из-за ограниченного размера её нужно использовать аккуратно.

3. Что такое эффективный доступ к памяти и как его обеспечить?
Эффективный доступ в CUDA означает коалесцированный доступ к глобальной памяти, когда потоки одного warp обращаются к соседним адресам. 

Это достигается правильной организацией данных в массивах и такой индексацией, при которой соседние потоки работают с соседними элементами. Также важно избегать конфликтов при доступе к разделяемой памяти.

4. Какие сложности возникают при работе с большим объёмом данных на GPU?
Основные сложности связаны с ограниченным объёмом видеопамяти и затратами времени на передачу данных между CPU и GPU. Часто данные приходится обрабатывать частями, что усложняет код. Кроме того, увеличивается риск неэффективного доступа к памяти и снижения производительности.

5. Почему важно минимизировать доступ к глобальной памяти?
Глобальная память имеет большую задержку доступа по сравнению с регистрами и разделяемой памятью. Частые обращения к ней сильно замедляют выполнение программы, поэтому данные стараются как можно дольше хранить в быстрых типах памяти и использовать повторно.

6. Как использовать профилирование для анализа производительности CUDA-программ?
Профилирование позволяет определить, какие части программы работают медленно. С его помощью измеряют время выполнения ядер и копирования данных, анализируют эффективность использования памяти и ресурсов GPU. 

На основе этих данных принимаются решения, какие участки кода нужно оптимизировать.
