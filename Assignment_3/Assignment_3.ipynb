{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laCFlRcquG5f",
        "outputId": "1e1df6d3-e2ba-44ed-973e-c8a747cd4bd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 15 12:55:12 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 1 (25 баллов)**\n",
        "Реализуйте программу на CUDA для поэлементной обработки массива (например,\n",
        "умножение каждого элемента на число). Реализуйте две версии программы:\n",
        "1. с использованием только глобальной памяти;\n",
        "2. с использованием разделяемой памяти.\n",
        "Сравните время выполнения обеих реализаций для массива размером 1 000 000\n",
        "элементов."
      ],
      "metadata": {
        "id": "j_GcMjlGthHF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m22-xvNDtaWY",
        "outputId": "e4e36c63-a24e-4176-8394-c6010a78a91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile task1.cu\n",
        "#include <cuda_runtime.h>          // базовые функции CUDA (ядра, память, события)\n",
        "#include <cstdio>                 // printf\n",
        "#include <vector>                 // std::vector для работы с массивами на CPU\n",
        "#include <cmath>                  // fabs для проверки корректности\n",
        "\n",
        "// Макрос для проверки ошибок CUDA-вызовов\n",
        "#define CHECK(call) do { \\\n",
        "  cudaError_t err = (call); \\\n",
        "  if (err != cudaSuccess) { \\\n",
        "    printf(\"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while(0)\n",
        "\n",
        "// CUDA-ядро: поэлементное умножение массива с использованием только глобальной памяти\n",
        "__global__ void scale_global(float* a, float k, int n) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x; // глобальный индекс потока\n",
        "  if (i < n) {\n",
        "    a[i] *= k;                                  // умножаем элемент массива на число\n",
        "  }\n",
        "}\n",
        "\n",
        "// CUDA-ядро: поэлементное умножение с использованием разделяемой памяти\n",
        "__global__ void scale_shared(float* a, float k, int n) {\n",
        "  extern __shared__ float sdata[];               // динамическая shared memory\n",
        "  int tid = threadIdx.x;                         // локальный индекс потока\n",
        "  int i = blockIdx.x * blockDim.x + tid;         // глобальный индекс элемента\n",
        "\n",
        "  if (i < n) {\n",
        "    sdata[tid] = a[i];                           // загрузка данных из global в shared\n",
        "  }\n",
        "  __syncthreads();                               // синхронизация потоков блока\n",
        "\n",
        "  if (i < n) {\n",
        "    sdata[tid] *= k;                             // умножение в shared memory\n",
        "  }\n",
        "  __syncthreads();                               // повторная синхронизация\n",
        "\n",
        "  if (i < n) {\n",
        "    a[i] = sdata[tid];                           // запись результата обратно в global\n",
        "  }\n",
        "}\n",
        "\n",
        "// Функция для измерения времени выполнения CUDA-ядра\n",
        "template <typename KernelFunc>\n",
        "float benchmark(KernelFunc kernel,\n",
        "                float* d_a,\n",
        "                float k,\n",
        "                int n,\n",
        "                dim3 grid,\n",
        "                dim3 block,\n",
        "                size_t shmem_bytes,\n",
        "                int iters) {\n",
        "\n",
        "  cudaEvent_t start, stop;                       // CUDA-события для тайминга\n",
        "  CHECK(cudaEventCreate(&start));\n",
        "  CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "  kernel<<<grid, block, shmem_bytes>>>(d_a, k, n); // прогрев ядра\n",
        "  CHECK(cudaGetLastError());\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  CHECK(cudaEventRecord(start));                 // старт измерения времени\n",
        "  for (int t = 0; t < iters; ++t) {\n",
        "    kernel<<<grid, block, shmem_bytes>>>(d_a, k, n); // многократный запуск ядра\n",
        "  }\n",
        "  CHECK(cudaEventRecord(stop));                  // окончание измерения\n",
        "\n",
        "  CHECK(cudaGetLastError());\n",
        "  CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CHECK(cudaEventElapsedTime(&ms, start, stop)); // вычисление времени в миллисекундах\n",
        "\n",
        "  CHECK(cudaEventDestroy(start));\n",
        "  CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "  return ms / iters;                             // среднее время одного запуска\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 1'000'000;                       // размер массива\n",
        "  const float k = 1.2345f;                       // коэффициент умножения\n",
        "  const int iters = 200;                         // число итераций для замера времени\n",
        "\n",
        "  std::vector<float> h_a(N);                     // массив на CPU\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    h_a[i] = 1.0f + (i % 100) * 0.01f;            // инициализация данных\n",
        "  }\n",
        "\n",
        "  float* d_a = nullptr;                          // указатель на массив в памяти GPU\n",
        "  CHECK(cudaMalloc(&d_a, N * sizeof(float)));    // выделение памяти на GPU\n",
        "\n",
        "  int blockSize = 256;                           // число потоков в блоке\n",
        "  dim3 block(blockSize);                         // конфигурация блока\n",
        "  dim3 grid((N + blockSize - 1) / blockSize);    // число блоков в сетке\n",
        "\n",
        "  CHECK(cudaMemcpy(d_a, h_a.data(),\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));     // копирование данных на GPU\n",
        "\n",
        "  float ms_global = benchmark(scale_global,      // измерение времени версии с global memory\n",
        "                              d_a, k, N,\n",
        "                              grid, block,\n",
        "                              0,\n",
        "                              iters);\n",
        "\n",
        "  CHECK(cudaMemcpy(d_a, h_a.data(),\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));     // повторная загрузка исходных данных\n",
        "\n",
        "  size_t shmem = blockSize * sizeof(float);      // размер shared memory на блок\n",
        "\n",
        "  float ms_shared = benchmark(scale_shared,      // измерение времени версии с shared memory\n",
        "                              d_a, k, N,\n",
        "                              grid, block,\n",
        "                              shmem,\n",
        "                              iters);\n",
        "\n",
        "  std::vector<float> out(N);                     // массив для результата\n",
        "  CHECK(cudaMemcpy(out.data(), d_a,\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyDeviceToHost));     // копирование результата на CPU\n",
        "\n",
        "  bool ok = true;                                // проверка корректности\n",
        "  for (int i = 0; i < 5; ++i) {\n",
        "    float ref = h_a[i] * k;\n",
        "    if (fabs(out[i] - ref) > 1e-6f) {\n",
        "      ok = false;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"N = %d, block = %d, iters = %d\\n\", N, blockSize, iters);\n",
        "  printf(\"Avg kernel time (global) = %.6f ms\\n\", ms_global);\n",
        "  printf(\"Avg kernel time (shared) = %.6f ms\\n\", ms_shared);\n",
        "\n",
        "  if (ms_shared > 0.0f) {\n",
        "    printf(\"Speedup (global/shared) = %.3fx\\n\", ms_global / ms_shared);\n",
        "  }\n",
        "\n",
        "  CHECK(cudaFree(d_a));                          // освобождение памяти GPU\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 task1.cu -o task1 \\\n",
        "  -gencode arch=compute_75,code=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCT6zs3Et4-S",
        "outputId": "0b924363-4cc5-487f-82c4-ed282af2fa62"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mtask1.cu(125)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"ok\"\u001b[0m was set but never used\n",
            "    bool ok = true;\n",
            "         ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./task1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp3htl7Uuczu",
        "outputId": "ad9979fd-36d6-45b9-b2ae-188877038574"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 1000000, block = 256, iters = 200\n",
            "Avg kernel time (global) = 0.025876 ms\n",
            "Avg kernel time (shared) = 0.034202 ms\n",
            "Speedup (global/shared) = 0.757x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 2 (25 баллов)**\n",
        "Реализуйте CUDA-программу для поэлементного сложения двух массивов. Исследуйте\n",
        "влияние размера блока потоков на производительность программы. Проведите замеры\n",
        "времени для как минимум трёх различных размеров блока."
      ],
      "metadata": {
        "id": "Cl17buVhtgLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task2.cu\n",
        "#include <cuda_runtime.h>          // основные CUDA-функции\n",
        "#include <cstdio>                 // printf\n",
        "#include <vector>                 // std::vector для массивов на CPU\n",
        "#include <cmath>                  // fabs для проверки корректности\n",
        "\n",
        "// Макрос для проверки ошибок CUDA\n",
        "#define CHECK(call) do { \\\n",
        "  cudaError_t err = (call); \\\n",
        "  if (err != cudaSuccess) { \\\n",
        "    printf(\"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while (0)\n",
        "\n",
        "// CUDA-ядро для поэлементного сложения двух массивов\n",
        "__global__ void add_arrays(const float* __restrict__ a,\n",
        "                           const float* __restrict__ b,\n",
        "                           float* __restrict__ c,\n",
        "                           int n) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x; // глобальный индекс элемента\n",
        "  if (i < n) {\n",
        "    c[i] = a[i] + b[i];                          // сложение элементов\n",
        "  }\n",
        "}\n",
        "\n",
        "// Функция для измерения времени выполнения CUDA-ядра\n",
        "float benchmark_add(const float* d_a,\n",
        "                    const float* d_b,\n",
        "                    float* d_c,\n",
        "                    int n,\n",
        "                    int blockSize,\n",
        "                    int iters) {\n",
        "\n",
        "  dim3 block(blockSize);                         // конфигурация блока\n",
        "  dim3 grid((n + blockSize - 1) / blockSize);    // конфигурация сетки\n",
        "\n",
        "  cudaEvent_t start, stop;                       // события для тайминга\n",
        "  CHECK(cudaEventCreate(&start));\n",
        "  CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "  add_arrays<<<grid, block>>>(d_a, d_b, d_c, n); // прогрев ядра\n",
        "  CHECK(cudaGetLastError());\n",
        "  CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  CHECK(cudaEventRecord(start));                 // старт измерения времени\n",
        "  for (int t = 0; t < iters; ++t) {\n",
        "    add_arrays<<<grid, block>>>(d_a, d_b, d_c, n); // повторные запуски ядра\n",
        "  }\n",
        "  CHECK(cudaEventRecord(stop));                  // окончание измерения\n",
        "\n",
        "  CHECK(cudaGetLastError());\n",
        "  CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CHECK(cudaEventElapsedTime(&ms, start, stop)); // время в миллисекундах\n",
        "\n",
        "  CHECK(cudaEventDestroy(start));\n",
        "  CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "  return ms / iters;                             // среднее время одного запуска\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 1'000'000;                       // размер массивов\n",
        "  const int iters = 300;                         // число итераций для замеров\n",
        "\n",
        "  const int blockSizes[] = {64, 128, 256, 512};  // тестируемые размеры блока\n",
        "  const int numTests = sizeof(blockSizes) / sizeof(blockSizes[0]);\n",
        "\n",
        "  std::vector<float> h_a(N), h_b(N), h_c(N);     // массивы на CPU\n",
        "  for (int i = 0; i < N; ++i) {\n",
        "    h_a[i] = 0.1f * (i % 1000);                  // инициализация первого массива\n",
        "    h_b[i] = 0.2f * ((i + 7) % 1000);            // инициализация второго массива\n",
        "  }\n",
        "\n",
        "  float *d_a = nullptr, *d_b = nullptr, *d_c = nullptr; // указатели на GPU\n",
        "  CHECK(cudaMalloc(&d_a, N * sizeof(float)));    // выделение памяти на GPU\n",
        "  CHECK(cudaMalloc(&d_b, N * sizeof(float)));\n",
        "  CHECK(cudaMalloc(&d_c, N * sizeof(float)));\n",
        "\n",
        "  CHECK(cudaMemcpy(d_a, h_a.data(),\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));     // копирование данных на GPU\n",
        "  CHECK(cudaMemcpy(d_b, h_b.data(),\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));\n",
        "\n",
        "  {                                              // проверка корректности\n",
        "    int bs = 256;\n",
        "    dim3 block(bs);\n",
        "    dim3 grid((N + bs - 1) / bs);\n",
        "    add_arrays<<<grid, block>>>(d_a, d_b, d_c, N);\n",
        "    CHECK(cudaGetLastError());\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    CHECK(cudaMemcpy(h_c.data(), d_c,\n",
        "                     N * sizeof(float),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "\n",
        "    bool ok = true;\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "      float ref = h_a[i] + h_b[i];\n",
        "      if (fabs(h_c[i] - ref) > 1e-6f) {\n",
        "        ok = false;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"N = %d, iters = %d\\n\", N, iters);\n",
        "  printf(\"BlockSize | AvgKernelTime (ms)\\n\");\n",
        "\n",
        "  for (int t = 0; t < numTests; ++t) {\n",
        "    int bs = blockSizes[t];                      // текущий размер блока\n",
        "    float ms = benchmark_add(d_a, d_b, d_c,\n",
        "                             N, bs, iters);     // измерение времени\n",
        "    printf(\"%8d | %0.6f\\n\", bs, ms);\n",
        "  }\n",
        "\n",
        "  CHECK(cudaFree(d_a));                          // освобождение памяти GPU\n",
        "  CHECK(cudaFree(d_b));\n",
        "  CHECK(cudaFree(d_c));\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImORf5-6thdn",
        "outputId": "aeef3f90-4fc4-4d26-fb9f-b345594bc2fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 task2.cu -o task2 \\\n",
        "  -gencode arch=compute_75,code=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vtybwQAvpMP",
        "outputId": "7ab46c16-554b-4d18-cf2a-d7c8c972552e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mtask2.cu(99)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"ok\"\u001b[0m was set but never used\n",
            "      bool ok = true;\n",
            "           ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./task2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS1tsaiGv2CU",
        "outputId": "94dea312-2c4e-4c74-ab1d-761761cd15b8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 1000000, iters = 300\n",
            "BlockSize | AvgKernelTime (ms)\n",
            "      64 | 0.050444\n",
            "     128 | 0.049326\n",
            "     256 | 0.049288\n",
            "     512 | 0.049429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 3 (25 баллов)**\n",
        "Реализуйте CUDA-программу для обработки массива, демонстрирующую\n",
        "коалесцированный и некоалесцированный доступ к глобальной памяти. Сравните время\n",
        "выполнения обеих реализаций для массива размером 1 000 000 элементов"
      ],
      "metadata": {
        "id": "OqnABWQ0thqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task3.cu\n",
        "#include <cuda_runtime.h>          // CUDA API: память, события, запуск ядер\n",
        "#include <cstdio>                 // printf\n",
        "#include <vector>                 // std::vector для данных на CPU\n",
        "#include <cmath>                  // fabs для сравнения float\n",
        "#include <cstdint>                // целочисленные типы фиксированной ширины (на всякий случай)\n",
        "\n",
        "// Макрос: проверка ошибок CUDA-вызовов\n",
        "#define CHECK(call) do { \\\n",
        "  cudaError_t err = (call); \\\n",
        "  if (err != cudaSuccess) { \\\n",
        "    printf(\"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while (0)\n",
        "\n",
        "// Коалесцированный доступ: потоки читают/пишут соседние элементы\n",
        "__global__ void kernel_coalesced(const float* __restrict__ in,\n",
        "                                 float* __restrict__ out,\n",
        "                                 float k,\n",
        "                                 int n) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x; // глобальный индекс элемента\n",
        "  if (i < n) {\n",
        "    out[i] = in[i] * k;                          // простая операция для нагрузки на память\n",
        "  }\n",
        "}\n",
        "\n",
        "// Некоалесцированный доступ: потоки обращаются к данным с большим шагом (stride)\n",
        "__global__ void kernel_uncoalesced(const float* __restrict__ in,\n",
        "                                  float* __restrict__ out,\n",
        "                                  float k,\n",
        "                                  int n,\n",
        "                                  int stride) {\n",
        "  int tid = blockIdx.x * blockDim.x + threadIdx.x; // глобальный индекс потока\n",
        "  int i = tid * stride;                             // разреженный индекс элемента\n",
        "  if (i < n) {\n",
        "    out[i] = in[i] * k;                             // выполняем ту же операцию\n",
        "  }\n",
        "}\n",
        "\n",
        "// Замер времени: launch-функция передается как лямбда, возвращаем среднее время запуска\n",
        "template <typename LaunchFunc>\n",
        "float benchmark(LaunchFunc launch, int iters) {\n",
        "  cudaEvent_t start, stop;                        // события для измерения времени на GPU\n",
        "  CHECK(cudaEventCreate(&start));                 // создаём событие старта\n",
        "  CHECK(cudaEventCreate(&stop));                  // создаём событие окончания\n",
        "\n",
        "  launch();                                       // прогрев (1 запуск)\n",
        "  CHECK(cudaDeviceSynchronize());                 // ждём завершения прогрева\n",
        "\n",
        "  CHECK(cudaEventRecord(start));                  // отмечаем старт\n",
        "  for (int t = 0; t < iters; ++t) {               // повторяем запуск много раз\n",
        "    launch();                                     // запуск ядра\n",
        "  }\n",
        "  CHECK(cudaEventRecord(stop));                   // отмечаем стоп\n",
        "\n",
        "  CHECK(cudaEventSynchronize(stop));              // ждём, пока GPU закончит\n",
        "\n",
        "  float ms = 0.0f;                                // переменная для времени в миллисекундах\n",
        "  CHECK(cudaEventElapsedTime(&ms, start, stop));  // считаем длительность между событиями\n",
        "\n",
        "  CHECK(cudaEventDestroy(start));                 // удаляем событие старта\n",
        "  CHECK(cudaEventDestroy(stop));                  // удаляем событие стопа\n",
        "\n",
        "  return ms / iters;                              // среднее время одного запуска ядра\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 1'000'000;                        // размер массива\n",
        "  const float k = 1.2345f;                        // множитель\n",
        "  const int iters = 200;                          // число итераций для усреднения времени\n",
        "\n",
        "  const int blockSize = 256;                      // размер блока потоков\n",
        "  dim3 block(blockSize);                          // блок: blockSize потоков\n",
        "  dim3 grid_coal((N + blockSize - 1) / blockSize);// сетка для коалесцированного ядра\n",
        "\n",
        "  const int stride = 32 * 8;                      // шаг, кратный warp=32, чтобы ломать коалесцирование\n",
        "  int N_eff = (N + stride - 1) / stride;          // сколько элементов реально обработаем при stride\n",
        "  dim3 grid_uncoal((N_eff + blockSize - 1) / blockSize); // сетка для некоалесцированного ядра\n",
        "\n",
        "  std::vector<float> h_in(N);                     // входной массив на CPU\n",
        "  std::vector<float> h_out(N, 0.0f);              // выходной массив на CPU\n",
        "  for (int i = 0; i < N; ++i) {                   // инициализация входных данных\n",
        "    h_in[i] = 1.0f + 0.001f * (i % 1000);         // простые значения\n",
        "  }\n",
        "\n",
        "  float *d_in = nullptr;                          // указатель на входной массив в GPU\n",
        "  float *d_out = nullptr;                         // указатель на выходной массив в GPU\n",
        "  CHECK(cudaMalloc(&d_in, N * sizeof(float)));    // выделяем память под вход\n",
        "  CHECK(cudaMalloc(&d_out, N * sizeof(float)));   // выделяем память под выход\n",
        "\n",
        "  CHECK(cudaMemcpy(d_in, h_in.data(),             // копируем входные данные на GPU\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));\n",
        "\n",
        "  CHECK(cudaMemset(d_out, 0, N * sizeof(float))); // обнуляем выходной массив на GPU\n",
        "\n",
        "  auto launch_coal = [&]() {                      // лямбда: запуск коалесцированного ядра\n",
        "    kernel_coalesced<<<grid_coal, block>>>(d_in, d_out, k, N); // запуск ядра\n",
        "    CHECK(cudaGetLastError());                    // проверка ошибки запуска\n",
        "  };\n",
        "\n",
        "  float ms_coal = benchmark(launch_coal, iters);  // измеряем время коалесцированного доступа\n",
        "\n",
        "  CHECK(cudaMemcpy(h_out.data(), d_out,           // копируем результат на CPU\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyDeviceToHost));\n",
        "\n",
        "  bool ok = true;                                 // флаг корректности\n",
        "  for (int i = 0; i < 10; ++i) {                  // проверяем первые 10 значений\n",
        "    float ref = h_in[i] * k;                      // ожидаемое значение\n",
        "    if (fabs(h_out[i] - ref) > 1e-6f) {           // сравнение с допуском\n",
        "      ok = false;                                 // если ошибка — ставим FAIL\n",
        "      break;                                      // выходим из цикла\n",
        "    }\n",
        "  }\n",
        "\n",
        "  CHECK(cudaMemset(d_out, 0, N * sizeof(float))); // снова обнуляем выход перед вторым тестом\n",
        "\n",
        "  auto launch_uncoal = [&]() {                    // лямбда: запуск некоалесцированного ядра\n",
        "    kernel_uncoalesced<<<grid_uncoal, block>>>(d_in, d_out, k, N, stride); // запуск ядра\n",
        "    CHECK(cudaGetLastError());                    // проверка ошибки запуска\n",
        "  };\n",
        "\n",
        "  float ms_uncoal = benchmark(launch_uncoal, iters); // измеряем время некоалесцированного доступа\n",
        "\n",
        "  CHECK(cudaMemcpy(h_out.data(), d_out,           // копируем результат обратно на CPU\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyDeviceToHost));\n",
        "\n",
        "  bool ok2 = true;                                // флаг корректности второй версии\n",
        "  for (int t = 0; t < 10; ++t) {                  // проверяем 10 точек, которые реально считались\n",
        "    int idx = t * stride;                         // индекс элемента, который обрабатывался\n",
        "    if (idx >= N) break;                          // защита от выхода за границы\n",
        "    float ref = h_in[idx] * k;                    // ожидаемое значение\n",
        "    if (fabs(h_out[idx] - ref) > 1e-6f) {         // сравнение с допуском\n",
        "      ok2 = false;                                // если ошибка — FAIL\n",
        "      break;                                      // выходим\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"N = %d, block = %d, iters = %d\\n\", N, blockSize, iters); // печать параметров теста\n",
        "  printf(\"\\n\");                                   // пустая строка для читаемости\n",
        "\n",
        "  printf(\"Stride (uncoalesced) = %d  -> processed elements per launch ~ %d\\n\", stride, N_eff); // сколько элементов обрабатывается\n",
        "  printf(\"\\nTiming (avg per kernel launch):\\n\");  // заголовок блока с временами\n",
        "  printf(\"  Coalesced   : %.6f ms  (processes %d elements)\\n\", ms_coal, N); // время коалесцированной версии\n",
        "  printf(\"  Uncoalesced : %.6f ms  (processes ~%d elements)\\n\", ms_uncoal, N_eff); // время разреженной версии\n",
        "\n",
        "  double ns_per_elem_coal = (ms_coal * 1e6) / (double)N;          // перевод в нс на элемент (коалесц.)\n",
        "  double ns_per_elem_uncoal = (ms_uncoal * 1e6) / (double)N_eff;  // перевод в нс на элемент (некоалесц.)\n",
        "\n",
        "  printf(\"\\nNormalized time:\\n\");                 // заголовок нормализованного времени\n",
        "  printf(\"  Coalesced   : %.3f ns/element\\n\", ns_per_elem_coal);   // нс/элемент для коалесцированного доступа\n",
        "  printf(\"  Uncoalesced : %.3f ns/element\\n\", ns_per_elem_uncoal); // нс/элемент для некоалесцированного доступа\n",
        "\n",
        "  if (ns_per_elem_uncoal > 0.0) {                // защита от деления на ноль\n",
        "    printf(\"\\nSlowdown (uncoalesced vs coalesced) per element: %.2fx\\n\",\n",
        "           ns_per_elem_uncoal / ns_per_elem_coal); // во сколько раз хуже некоалесцированный доступ\n",
        "  }\n",
        "\n",
        "  CHECK(cudaFree(d_in));                          // освобождаем память входа на GPU\n",
        "  CHECK(cudaFree(d_out));                         // освобождаем память выхода на GPU\n",
        "  return 0;                                       // успешное завершение программы\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDG2CptHth76",
        "outputId": "34f5353a-c0ad-4d96-c8c8-01fd1a07f810"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 task3.cu -o task3 \\\n",
        "  -gencode arch=compute_75,code=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YcE7qGmw_Sl",
        "outputId": "867bf1a6-3774-47da-c198-a3a784d86d90"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mtask3.cu(108)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"ok\"\u001b[0m was set but never used\n",
            "    bool ok = true;\n",
            "         ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtask3.cu(130)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"ok2\"\u001b[0m was set but never used\n",
            "    bool ok2 = true;\n",
            "         ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./task3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nhqu6WDxGk3",
        "outputId": "b6d09f81-e308-4964-88d5-5cfd03e3db81"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 1000000, block = 256, iters = 200\n",
            "\n",
            "Stride (uncoalesced) = 256  -> processed elements per launch ~ 3907\n",
            "\n",
            "Timing (avg per kernel launch):\n",
            "  Coalesced   : 0.038017 ms  (processes 1000000 elements)\n",
            "  Uncoalesced : 0.004848 ms  (processes ~3907 elements)\n",
            "\n",
            "Normalized time:\n",
            "  Coalesced   : 0.038 ns/element\n",
            "  Uncoalesced : 1.241 ns/element\n",
            "\n",
            "Slowdown (uncoalesced vs coalesced) per element: 32.64x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 4 (25 баллов)**\n",
        "Для одной из реализованных в предыдущих заданиях CUDA-программ подберите\n",
        "оптимальные параметры конфигурации сетки и блоков потоков. Сравните\n",
        "производительность неоптимальной и оптимизированной конфигураций."
      ],
      "metadata": {
        "id": "u9ef3rkPtiIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task4.cu\n",
        "#include <cuda_runtime.h>          // CUDA API: запуск ядер, память, свойства устройства\n",
        "#include <cstdio>                 // printf\n",
        "#include <vector>                 // std::vector для массивов на CPU\n",
        "#include <cmath>                  // fabs для сравнения float\n",
        "#include <limits>                 // numeric_limits для поиска минимума\n",
        "\n",
        "// Макрос: проверка ошибок CUDA-вызовов\n",
        "#define CHECK(call) do { \\\n",
        "  cudaError_t err = (call); \\\n",
        "  if (err != cudaSuccess) { \\\n",
        "    printf(\"CUDA error %s:%d: %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while (0)\n",
        "\n",
        "// CUDA-ядро: поэлементное сложение с grid-stride loop (работает для любых grid/block)\n",
        "__global__ void add_arrays_gs(const float* __restrict__ a,\n",
        "                             const float* __restrict__ b,\n",
        "                             float* __restrict__ c,\n",
        "                             int n) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x; // стартовый индекс для потока\n",
        "  int stride = blockDim.x * gridDim.x;             // шаг между обрабатываемыми элементами\n",
        "  for (int i = idx; i < n; i += stride) {          // каждый поток обрабатывает несколько элементов\n",
        "    c[i] = a[i] + b[i];                            // основная операция: сложение\n",
        "  }\n",
        "}\n",
        "\n",
        "// Функция измерения времени: один запуск ядра усредняется по iters\n",
        "float benchmark_add(const float* d_a,\n",
        "                    const float* d_b,\n",
        "                    float* d_c,\n",
        "                    int n,\n",
        "                    int blockSize,\n",
        "                    int gridSize,\n",
        "                    int iters) {\n",
        "\n",
        "  cudaEvent_t start, stop;                         // события CUDA для тайминга\n",
        "  CHECK(cudaEventCreate(&start));                  // создаём событие старта\n",
        "  CHECK(cudaEventCreate(&stop));                   // создаём событие стопа\n",
        "\n",
        "  dim3 block(blockSize);                           // задаём размер блока потоков\n",
        "  dim3 grid(gridSize);                             // задаём число блоков в сетке\n",
        "\n",
        "  add_arrays_gs<<<grid, block>>>(d_a, d_b, d_c, n); // прогрев (первый запуск)\n",
        "  CHECK(cudaGetLastError());                       // проверка ошибки запуска\n",
        "  CHECK(cudaDeviceSynchronize());                  // ждём завершения прогрева\n",
        "\n",
        "  CHECK(cudaEventRecord(start));                   // старт измерения времени\n",
        "  for (int t = 0; t < iters; ++t) {                // многократно запускаем ядро\n",
        "    add_arrays_gs<<<grid, block>>>(d_a, d_b, d_c, n); // запуск ядра с текущей конфигурацией\n",
        "  }\n",
        "  CHECK(cudaEventRecord(stop));                    // стоп измерения\n",
        "\n",
        "  CHECK(cudaGetLastError());                       // проверяем, не было ли ошибки запуска\n",
        "  CHECK(cudaEventSynchronize(stop));               // ждём, пока GPU закончит\n",
        "\n",
        "  float ms = 0.0f;                                 // сюда запишем время в миллисекундах\n",
        "  CHECK(cudaEventElapsedTime(&ms, start, stop));   // считаем длительность между start и stop\n",
        "\n",
        "  CHECK(cudaEventDestroy(start));                  // удаляем событие старта\n",
        "  CHECK(cudaEventDestroy(stop));                   // удаляем событие стопа\n",
        "\n",
        "  return ms / iters;                               // возвращаем среднее время одного запуска\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 1'000'000;                         // размер массивов\n",
        "  const int iters = 300;                           // число итераций для точного усреднения\n",
        "\n",
        "  std::vector<float> h_a(N), h_b(N), h_c(N);       // массивы на CPU\n",
        "  for (int i = 0; i < N; ++i) {                    // заполняем тестовыми значениями\n",
        "    h_a[i] = 0.1f * (i % 1000);                    // значения для A\n",
        "    h_b[i] = 0.2f * ((i + 7) % 1000);              // значения для B\n",
        "  }\n",
        "\n",
        "  float *d_a = nullptr, *d_b = nullptr, *d_c = nullptr; // указатели на GPU\n",
        "  CHECK(cudaMalloc(&d_a, N * sizeof(float)));      // выделяем память под A\n",
        "  CHECK(cudaMalloc(&d_b, N * sizeof(float)));      // выделяем память под B\n",
        "  CHECK(cudaMalloc(&d_c, N * sizeof(float)));      // выделяем память под C\n",
        "\n",
        "  CHECK(cudaMemcpy(d_a, h_a.data(),                // копируем A на GPU\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));\n",
        "  CHECK(cudaMemcpy(d_b, h_b.data(),                // копируем B на GPU\n",
        "                   N * sizeof(float),\n",
        "                   cudaMemcpyHostToDevice));\n",
        "\n",
        "  {                                                // отдельный блок: проверка корректности\n",
        "    int bs = 256;                                  // берём типичный размер блока\n",
        "    int gs = (N + bs - 1) / bs;                    // сетка на весь массив (обычная формула)\n",
        "    add_arrays_gs<<<gs, bs>>>(d_a, d_b, d_c, N);   // один запуск ядра\n",
        "    CHECK(cudaGetLastError());                     // проверка ошибок\n",
        "    CHECK(cudaDeviceSynchronize());                // ждём завершения\n",
        "    CHECK(cudaMemcpy(h_c.data(), d_c,              // копируем результат на CPU\n",
        "                     N * sizeof(float),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "\n",
        "    bool ok = true;                                // флаг корректности\n",
        "    for (int i = 0; i < 10; ++i) {                 // проверяем первые 10 элементов\n",
        "      float ref = h_a[i] + h_b[i];                 // эталонное значение\n",
        "      if (fabs(h_c[i] - ref) > 1e-6f) {            // сравнение с допуском\n",
        "        ok = false;                                // если ошибка — ставим FAIL\n",
        "        break;                                     // выходим из цикла\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  cudaDeviceProp prop{};                           // структура с параметрами GPU\n",
        "  CHECK(cudaGetDeviceProperties(&prop, 0));        // получаем свойства устройства 0\n",
        "  int SM = prop.multiProcessorCount;               // число SM (Streaming Multiprocessors)\n",
        "\n",
        "  const int blockSizes[] = {32, 64, 128, 256, 512, 1024}; // кандидаты размеров блока\n",
        "  const int numBS = sizeof(blockSizes) / sizeof(blockSizes[0]); // сколько вариантов blockSize\n",
        "\n",
        "  const int gridMults[] = {1, 2, 4, 8, 16};        // множители для gridSize относительно SM\n",
        "  const int numGM = sizeof(gridMults) / sizeof(gridMults[0]); // сколько вариантов множителя\n",
        "\n",
        "  printf(\"GPU: %s | SMs = %d\\n\", prop.name, SM);   // печать имени GPU и числа SM\n",
        "  printf(\"N = %d, iters = %d\\n\\n\", N, iters);      // печать параметров теста\n",
        "\n",
        "  float best_ms = std::numeric_limits<float>::infinity(); // лучшее (минимальное) время\n",
        "  int best_bs = -1;                                // лучший blockSize\n",
        "  int best_gs = -1;                                // лучший gridSize\n",
        "\n",
        "  float worst_ms = -1.0f;                          // худшее (максимальное) время\n",
        "  int worst_bs = -1;                               // худший blockSize\n",
        "  int worst_gs = -1;                               // худший gridSize\n",
        "\n",
        "  printf(\"Search results (avg ms per kernel):\\n\");  // заголовок таблицы\n",
        "  printf(\"Block | Grid  | AvgTime(ms)\\n\");          // названия колонок\n",
        "  printf(\"----- | ----- | ----------\\n\");           // разделитель\n",
        "\n",
        "  for (int bi = 0; bi < numBS; ++bi) {             // цикл по blockSize\n",
        "    int bs = blockSizes[bi];                       // текущий blockSize\n",
        "\n",
        "    for (int gi = 0; gi < numGM; ++gi) {           // цикл по gridSize\n",
        "      int gs = SM * gridMults[gi];                 // текущий gridSize = SM * множитель\n",
        "\n",
        "      float ms = benchmark_add(d_a, d_b, d_c,      // измеряем время выполнения\n",
        "                               N, bs, gs, iters);\n",
        "\n",
        "      printf(\"%5d | %5d | %0.6f\\n\", bs, gs, ms);    // печатаем строку таблицы\n",
        "\n",
        "      if (ms < best_ms) {                          // обновляем лучший результат\n",
        "        best_ms = ms;                              // сохраняем лучшее время\n",
        "        best_bs = bs;                              // сохраняем лучший blockSize\n",
        "        best_gs = gs;                              // сохраняем лучший gridSize\n",
        "      }\n",
        "\n",
        "      if (ms > worst_ms) {                         // обновляем худший результат\n",
        "        worst_ms = ms;                             // сохраняем худшее время\n",
        "        worst_bs = bs;                             // сохраняем худший blockSize\n",
        "        worst_gs = gs;                             // сохраняем худший gridSize\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"\\nBest (optimized) config:\\n\");           // вывод оптимальной конфигурации\n",
        "  printf(\"  blockSize = %d, gridSize = %d  -> %.6f ms\\n\",\n",
        "         best_bs, best_gs, best_ms);               // печать лучших параметров и времени\n",
        "\n",
        "  printf(\"\\nWorst (non-optimal) config (from tested set):\\n\"); // вывод неоптимальной конфигурации\n",
        "  printf(\"  blockSize = %d, gridSize = %d  -> %.6f ms\\n\",\n",
        "         worst_bs, worst_gs, worst_ms);            // печать худших параметров и времени\n",
        "\n",
        "  if (best_ms > 0.0f) {                            // защита от деления на ноль\n",
        "    printf(\"\\nSpeedup (worst / best) = %.2fx\\n\",   // во сколько раз лучше оптимальная\n",
        "           worst_ms / best_ms);\n",
        "  }\n",
        "\n",
        "  CHECK(cudaFree(d_a));                            // освобождаем память A на GPU\n",
        "  CHECK(cudaFree(d_b));                            // освобождаем память B на GPU\n",
        "  CHECK(cudaFree(d_c));                            // освобождаем память C на GPU\n",
        "  return 0;                                        // завершение программы\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAzSkLD-tiYJ",
        "outputId": "0fbc3abe-d3fa-4ae0-8ad0-ca0995a85aa6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -std=c++17 task4.cu -o task4 \\\n",
        "  -gencode arch=compute_75,code=sm_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnLerHUayAN-",
        "outputId": "ffa6cc3e-cb0a-4484-8e48-a66c43867300"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mtask4.cu(98)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"ok\"\u001b[0m was set but never used\n",
            "      bool ok = true;\n",
            "           ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./task4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svg6Sa0lyEqu",
        "outputId": "b105ed95-b992-4aed-8ce6-ab62a4c0ddbe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4 | SMs = 40\n",
            "N = 1000000, iters = 300\n",
            "\n",
            "Search results (avg ms per kernel):\n",
            "Block | Grid  | AvgTime(ms)\n",
            "----- | ----- | ----------\n",
            "   32 |    40 | 0.169145\n",
            "   32 |    80 | 0.104740\n",
            "   32 |   160 | 0.063243\n",
            "   32 |   320 | 0.055341\n",
            "   32 |   640 | 0.053347\n",
            "   64 |    40 | 0.084494\n",
            "   64 |    80 | 0.057094\n",
            "   64 |   160 | 0.052456\n",
            "   64 |   320 | 0.052231\n",
            "   64 |   640 | 0.053137\n",
            "  128 |    40 | 0.053811\n",
            "  128 |    80 | 0.051337\n",
            "  128 |   160 | 0.051584\n",
            "  128 |   320 | 0.052610\n",
            "  128 |   640 | 0.052661\n",
            "  256 |    40 | 0.051101\n",
            "  256 |    80 | 0.051507\n",
            "  256 |   160 | 0.052941\n",
            "  256 |   320 | 0.052755\n",
            "  256 |   640 | 0.051412\n",
            "  512 |    40 | 0.051998\n",
            "  512 |    80 | 0.053321\n",
            "  512 |   160 | 0.053102\n",
            "  512 |   320 | 0.051412\n",
            "  512 |   640 | 0.049760\n",
            " 1024 |    40 | 0.053679\n",
            " 1024 |    80 | 0.053116\n",
            " 1024 |   160 | 0.051233\n",
            " 1024 |   320 | 0.049747\n",
            " 1024 |   640 | 0.049365\n",
            "\n",
            "Best (optimized) config:\n",
            "  blockSize = 1024, gridSize = 640  -> 0.049365 ms\n",
            "\n",
            "Worst (non-optimal) config (from tested set):\n",
            "  blockSize = 32, gridSize = 40  -> 0.169145 ms\n",
            "\n",
            "Speedup (worst / best) = 3.43x\n"
          ]
        }
      ]
    }
  ]
}