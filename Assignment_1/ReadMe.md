Файлы по решению Assignment 1 по дисциплине Heterogeneous Parallelization. 

Магистрант: Asyl Aian. 

Группа: ADA-2401M.

Задание выполнено соответственно по задачам указанному в задаче. В файле 1_task.cpp решение 1 задачи, в 2_task.cpp - 2 задачи, 3_task.cpp - 3 задачи и соответствено в 4_task.cpp - 4 задача.

Файл main.cpp был прописан для последовательного запуска кодов задач, так как в Visual Studio коды писала в одном проекте.


Ответы на вопросы из Assignment 1: 
### 1. В чём отличие динамического массива от статического массива в языке C++?
**Статический массив** имеет фиксированный размер, который задаётся на этапе компиляции и После его нельзя изменить. 
**Динамический массив** создаётся во время выполнения программы с помощью оператора "new". Его размер можно определить в процессе работы программы.
### 2. Что такое указатель и зачем он используется при работе с динамической памятью?
**Указатель** — это переменная, которая хранит адрес другой переменной в памяти.
При работе с динамической памятью указатель используется для:
* хранения адреса выделенной области памяти,
* доступа к элементам динамического массива,
* использу.т при передаче данных в функции без копирования.
Без указателя невозможно получить доступ к динамически выделенной памяти.
### 3. Почему важно корректно освобождать память после использования динамических массивов?
Если динамическая память не освобождается с помощью `delete[]`, возникает **утечка памяти** — выделенная память остаётся занятой до завершения программы.
Это приводит к: увеличению потребления памяти, снижению производительности, сбоям и аварийному завершению программы при длительной работе.
### 4. В чём разница между последовательной и параллельной обработкой массива?
При **последовательной обработке** все элементы массива обрабатываются **одним потоком** строго по очереди.
При **параллельной обработке** массив делится на части, и разные элементы обрабатываются **одновременно несколькими потоками**, что может значительно ускорить вычисления на многоядерных процессорах.
### 5. Что делает директива `#pragma omp parallel for`?
Директива `#pragma omp parallel for`:
* создаёт группу потоков,
* автоматически распределяет итерации цикла `for` между потоками,
* выполняет тело цикла параллельно.
Она используется для распараллеливания циклов без необходимости вручную управлять потоками.
### 6. Для чего используется механизм `reduction` в OpenMP?
Механизм `reduction` используется для **безопасного объединения частичных результатов**, вычисленных разными потоками, в одно итоговое значение.
Часто применяется при:
* вычислении суммы,
* нахождении минимума или максимума,
* логических операциях.
### 7. Почему при параллельном вычислении суммы необходимо использовать `reduction`, а не обычную переменную?
Если несколько потоков одновременно изменяют одну и ту же переменную без `reduction`, возникает **(race condition)**.
`reduction`:
* создаёт локальную копию переменной для каждого потока,
* выполняет вычисления независимо,
* корректно объединяет результаты в конце параллельной области.
Без `reduction` результат будет некорректным и непредсказуемым.
### 8. Какие факторы могут привести к тому, что параллельная версия программы будет работать медленнее последовательной?
Параллельная программа может работать медленнее из-за:
* накладных расходов на создание и управление потоками,
* слишком малого объёма данных,
* неравномерного распределения нагрузки между потоками,
* частых операций синхронизации,
* конфликтов доступа к общей памяти,
* ограничений пропускной способности памяти.
