{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "1. Реализовать параллельную сортировку слиянием на CUDA:\n",
        "\n",
        "● Разделите массив на блоки, каждый из которых будет обрабатываться\n",
        "одним блоком потоков.\n",
        "\n",
        "● Сортируйте блоки параллельно и сливайте их по парам.\n"
      ],
      "metadata": {
        "id": "qp_T9qv62K_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "4. Сравнение производительности:\n",
        "\n",
        "● Реализуйте последовательные версии этих алгоритмов на CPU.\n",
        "\n",
        "● Измерьте время выполнения каждой сортировки на CPU и на GPU для\n",
        "массивов разного размера (например, 10,000, 100,000 и 1,000,000\n",
        "элементов).\n",
        "\n",
        "● Сравните производительность и сделайте выводы."
      ],
      "metadata": {
        "id": "9hvVr5-q2kD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUAFaso2KkH1",
        "outputId": "fee4a6d0-dd53-411d-8700-7817839ed470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 25 04:36:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi #это утилита NVIDIA, которая показывает состояние видеокарты.\n",
        "!nvcc --version #это CUDA-компилятор"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 1main.cu\n",
        "// Подключаем CUDA Runtime API (cudaMalloc, cudaMemcpy и т.д.)\n",
        "#include <cuda_runtime.h>\n",
        "// Подключаем определения для threadIdx, blockIdx и др.\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "// Стандартные библиотеки C++\n",
        "#include <algorithm>   // stable_sort\n",
        "#include <chrono>      // измерение времени\n",
        "#include <climits>     // INT_MAX\n",
        "#include <iostream>    // cout\n",
        "#include <random>      // генератор случайных чисел\n",
        "#include <vector>      // std::vector\n",
        "\n",
        "// Макрос для проверки ошибок CUDA-вызовов\n",
        "// Если ошибка произошла — выводим сообщение и завершаем программу\n",
        "#define CUDA_CHECK(call) do {                                \\\n",
        "    cudaError_t e = (call);                                  \\\n",
        "    if (e != cudaSuccess) {                                  \\\n",
        "        std::cerr << \"CUDA error: \"                           \\\n",
        "                  << cudaGetErrorString(e)                    \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__    \\\n",
        "                  << std::endl;                               \\\n",
        "        std::exit(1);                                        \\\n",
        "    }                                                        \\\n",
        "} while(0)\n",
        "\n",
        "// Функция проверки: отсортирован ли массив по возрастанию (CPU)\n",
        "static bool is_sorted_cpu(const std::vector<int>& a) {\n",
        "    for (size_t i = 1; i < a.size(); ++i)\n",
        "        if (a[i-1] > a[i]) return false;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// 1) СОРТИРОВКА КУСКОВ НА GPU\n",
        "// Размер одного блока данных, сортируемого одним CUDA-блоком\n",
        "// Должен быть степенью двойки (для bitonic sort)\n",
        "constexpr int CHUNK = 1024;\n",
        "\n",
        "// CUDA-ядро: каждый блок сортирует свой участок массива\n",
        "__global__ void chunk_sort_bitonic(const int* in, int* out, int n) {\n",
        "\n",
        "    // Shared memory — быстрая память, общая для потоков одного блока\n",
        "    __shared__ int s[CHUNK];\n",
        "\n",
        "    // Начальный индекс текущего блока в глобальном массиве\n",
        "    int base = (int)blockIdx.x * CHUNK;\n",
        "    // Индекс потока внутри блока\n",
        "    int tid  = (int)threadIdx.x;\n",
        "\n",
        "    // Загружаем данные из глобальной памяти в shared memory\n",
        "    // Если выходим за пределы массива — заполняем INT_MAX\n",
        "    for (int i = tid; i < CHUNK; i += (int)blockDim.x) {\n",
        "        int idx = base + i;\n",
        "        s[i] = (idx < n) ? in[idx] : INT_MAX;\n",
        "    }\n",
        "\n",
        "    // Ждём, пока все потоки загрузят данные\n",
        "    __syncthreads();\n",
        "\n",
        "    // Реализация bitonic sort в shared memory\n",
        "    for (int k = 2; k <= CHUNK; k <<= 1) {\n",
        "        for (int j = k >> 1; j > 0; j >>= 1) {\n",
        "            for (int i = tid; i < CHUNK; i += (int)blockDim.x) {\n",
        "\n",
        "                // Индекс элемента для сравнения (bitonic network)\n",
        "                int ixj = i ^ j;\n",
        "\n",
        "                if (ixj > i) {\n",
        "                    // Определяем направление сортировки\n",
        "                    bool ascending = ((i & k) == 0);\n",
        "\n",
        "                    int a = s[i];\n",
        "                    int b = s[ixj];\n",
        "\n",
        "                    // Меняем элементы местами при необходимости\n",
        "                    if ((ascending && a > b) || (!ascending && a < b)) {\n",
        "                        s[i] = b;\n",
        "                        s[ixj] = a;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            // Синхронизация потоков перед следующим шагом\n",
        "            __syncthreads();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Записываем отсортированный chunk обратно в глобальную память\n",
        "    for (int i = tid; i < CHUNK; i += (int)blockDim.x) {\n",
        "        int idx = base + i;\n",
        "        if (idx < n) out[idx] = s[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// 2) СЛИЯНИЕ ОТСОРТИРОВАННЫХ КУСКОВ (MERGE PASS)\n",
        "// Функция merge-path: находит позицию элемента при слиянии двух массивов\n",
        "__device__ int merge_path_search(const int* A, int aCount,\n",
        "                                 const int* B, int bCount,\n",
        "                                 int diag) {\n",
        "    int lo = max(0, diag - bCount);\n",
        "    int hi = min(diag, aCount);\n",
        "\n",
        "    while (lo < hi) {\n",
        "        int mid = (lo + hi) >> 1;\n",
        "        int j = diag - mid;\n",
        "\n",
        "        int A_left  = (mid > 0) ? A[mid - 1] : INT_MIN;\n",
        "        int A_right = (mid < aCount) ? A[mid] : INT_MAX;\n",
        "        int B_left  = (j > 0) ? B[j - 1] : INT_MIN;\n",
        "        int B_right = (j < bCount) ? B[j] : INT_MAX;\n",
        "\n",
        "        if (A_left > B_right) hi = mid;\n",
        "        else if (B_left >= A_right) lo = mid + 1;\n",
        "        else return mid;\n",
        "    }\n",
        "    return lo;\n",
        "}\n",
        "\n",
        "// CUDA-ядро: сливает два соседних отсортированных участка массива\n",
        "__global__ void merge_pass(const int* in, int* out, int n, int width) {\n",
        "\n",
        "    // Каждый блок отвечает за одну пару массивов\n",
        "    int pair = (int)blockIdx.x;\n",
        "    int left = pair * (2 * width);\n",
        "    if (left >= n) return;\n",
        "\n",
        "    int mid   = left + width;\n",
        "    int right = min(left + 2 * width, n);\n",
        "\n",
        "    int aCount = min(width, n - left);\n",
        "    int bCount = max(0, right - mid);\n",
        "\n",
        "    const int* A = in + left;\n",
        "    const int* B = in + mid;\n",
        "\n",
        "    int total = aCount + bCount;\n",
        "\n",
        "    int tid = (int)threadIdx.x;\n",
        "    int stride = (int)blockDim.x;\n",
        "\n",
        "    // Каждый поток обрабатывает несколько элементов результата\n",
        "    for (int diag = tid; diag < total; diag += stride) {\n",
        "        int i = merge_path_search(A, aCount, B, bCount, diag);\n",
        "        int j = diag - i;\n",
        "\n",
        "        int aVal = (i < aCount) ? A[i] : INT_MAX;\n",
        "        int bVal = (j < bCount) ? B[j] : INT_MAX;\n",
        "\n",
        "        out[left + diag] = (aVal <= bVal) ? aVal : bVal;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ОБЁРТКА GPU MERGE SORT\n",
        "void gpu_merge_sort(std::vector<int>& a, float& ms_total) {\n",
        "\n",
        "    int n = (int)a.size();\n",
        "    if (n == 0) { ms_total = 0; return; }\n",
        "\n",
        "    int* d_in  = nullptr;\n",
        "    int* d_tmp = nullptr;\n",
        "\n",
        "    // Выделяем память на GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_in,  n * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_tmp, n * sizeof(int)));\n",
        "\n",
        "    // Копируем данные с CPU на GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_in, a.data(), n * sizeof(int),\n",
        "                          cudaMemcpyHostToDevice));\n",
        "\n",
        "    // CUDA события для замера времени GPU\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "    // 1) Параллельная сортировка chunk'ов\n",
        "    int numChunks = (n + CHUNK - 1) / CHUNK;\n",
        "    chunk_sort_bitonic<<<numChunks, 256>>>(d_in, d_tmp, n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "\n",
        "    // 2) Последовательные проходы слияния (width удваивается)\n",
        "    int* src = d_tmp;\n",
        "    int* dst = d_in;\n",
        "\n",
        "    for (int width = CHUNK; width < n; width <<= 1) {\n",
        "        int numPairs = (n + 2 * width - 1) / (2 * width);\n",
        "        merge_pass<<<numPairs, 256>>>(src, dst, n, width);\n",
        "        CUDA_CHECK(cudaGetLastError());\n",
        "        std::swap(src, dst);\n",
        "    }\n",
        "\n",
        "    // Останавливаем таймер GPU\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&ms_total, start, stop));\n",
        "\n",
        "    // Копируем результат обратно на CPU\n",
        "    CUDA_CHECK(cudaMemcpy(a.data(), src, n * sizeof(int),\n",
        "                          cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Освобождаем ресурсы\n",
        "    CUDA_CHECK(cudaEventDestroy(start));\n",
        "    CUDA_CHECK(cudaEventDestroy(stop));\n",
        "    CUDA_CHECK(cudaFree(d_in));\n",
        "    CUDA_CHECK(cudaFree(d_tmp));\n",
        "}\n",
        "// MAIN\n",
        "int main() {\n",
        "\n",
        "    // Размеры массивов для тестирования\n",
        "    std::vector<int> sizes = {10000, 100000, 1000000};\n",
        "\n",
        "    // Генератор случайных чисел\n",
        "    std::mt19937 rng(12345);\n",
        "    std::uniform_int_distribution<int> dist(0, 1000000);\n",
        "\n",
        "    for (int N : sizes) {\n",
        "\n",
        "        // Генерируем входной массив\n",
        "        std::vector<int> a(N);\n",
        "        for (int i = 0; i < N; ++i)\n",
        "            a[i] = dist(rng);\n",
        "\n",
        "        // Копия для CPU-сортировки\n",
        "        std::vector<int> ref = a;\n",
        "\n",
        "        // CPU сортировка + замер времени\n",
        "        auto t0 = std::chrono::high_resolution_clock::now();\n",
        "        std::stable_sort(ref.begin(), ref.end());\n",
        "        auto t1 = std::chrono::high_resolution_clock::now();\n",
        "        double cpu_ms =\n",
        "            std::chrono::duration<double, std::milli>(t1 - t0).count();\n",
        "\n",
        "        // GPU сортировка\n",
        "        float gpu_ms = 0.0f;\n",
        "        gpu_merge_sort(a, gpu_ms);\n",
        "\n",
        "        // Проверка корректности\n",
        "        bool ok = (a == ref) && is_sorted_cpu(a);\n",
        "\n",
        "        // Вывод результатов\n",
        "        std::cout << \"\\nN = \" << N << \"\\n\";\n",
        "        std::cout << \"CPU stable_sort: \" << cpu_ms << \" ms\\n\";\n",
        "        std::cout << \"GPU MergeSort:   \" << gpu_ms << \" ms\\n\";\n",
        "        std::cout << \"Correct: \" << (ok ? \"YES\" : \"NO\") << \"\\n\";\n",
        "        if (gpu_ms > 0)\n",
        "            std::cout << \"Speedup CPU/GPU: \"\n",
        "                      << (cpu_ms / gpu_ms) << \"x\\n\";\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPpKOk1lKsM7",
        "outputId": "832bdf5d-b21b-4e7f-bbdb-a3e3536424c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 1main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O2 -arch=sm_75 1main.cu -o 1main #компиляция CUDA-программы\n",
        "!./1main #запуск программы\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9pUCQMeKsdG",
        "outputId": "48760ad2-3d05-41d9-caba-64d0e80c49c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "N = 10000\n",
            "CPU stable_sort: 0.907922 ms\n",
            "GPU MergeSort:   0.604128 ms\n",
            "Correct: YES\n",
            "Speedup CPU/GPU: 1.50286x\n",
            "\n",
            "N = 100000\n",
            "CPU stable_sort: 8.01978 ms\n",
            "GPU MergeSort:   4.50947 ms\n",
            "Correct: YES\n",
            "Speedup CPU/GPU: 1.77843x\n",
            "\n",
            "N = 1000000\n",
            "CPU stable_sort: 95.8275 ms\n",
            "GPU MergeSort:   57.1595 ms\n",
            "Correct: YES\n",
            "Speedup CPU/GPU: 1.67649x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "2. Реализовать параллельную быструю сортировку на CUDA:\n",
        "\n",
        "● Используйте параллельные потоки для деления массива по опорному\n",
        "элементу.\n",
        "\n",
        "● В каждом потоке выполняется быстрая сортировка на своей части\n",
        "массива."
      ],
      "metadata": {
        "id": "ucVryZTq2Ura"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "4. Сравнение производительности:\n",
        "\n",
        "● Реализуйте последовательные версии этих алгоритмов на CPU.\n",
        "\n",
        "● Измерьте время выполнения каждой сортировки на CPU и на GPU для\n",
        "массивов разного размера (например, 10,000, 100,000 и 1,000,000\n",
        "элементов).\n",
        "\n",
        "● Сравните производительность и сделайте выводы."
      ],
      "metadata": {
        "id": "jW6-P69V2s1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 2main.cu\n",
        "// Основной CUDA Runtime API\n",
        "#include <cuda_runtime.h>\n",
        "// Доступ к threadIdx, blockIdx, blockDim\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "// Стандартные библиотеки C++\n",
        "#include <algorithm>   // std::sort\n",
        "#include <chrono>      // измерение времени\n",
        "#include <climits>     // INT_MAX, INT_MIN\n",
        "#include <iostream>    // вывод в консоль\n",
        "#include <random>      // генерация случайных чисел\n",
        "#include <vector>      // std::vector\n",
        "\n",
        "// Макрос для проверки ошибок CUDA\n",
        "// Оборачивает каждый вызов CUDA и проверяет,\n",
        "// не вернула ли функция ошибку\n",
        "#define CUDA_CHECK(call) do {                                \\\n",
        "    cudaError_t e = (call);                                  \\\n",
        "    if (e != cudaSuccess) {                                  \\\n",
        "        std::cerr << \"CUDA error: \"                           \\\n",
        "                  << cudaGetErrorString(e)                    \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__    \\\n",
        "                  << std::endl;                               \\\n",
        "        std::exit(1);                                        \\\n",
        "    }                                                        \\\n",
        "} while(0)\n",
        "\n",
        "// Проверка отсортированности массива (CPU)\n",
        "static bool is_sorted_cpu(const std::vector<int>& a) {\n",
        "    // Проверяем, что каждый следующий элемент >= предыдущего\n",
        "    for (size_t i = 1; i < a.size(); ++i)\n",
        "        if (a[i - 1] > a[i]) return false;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// GPU MERGE PASS — используется для финального слияния chunk'ов\n",
        "// Функция merge-path (работает на GPU):\n",
        "// по диагональному индексу diag находит,\n",
        "// сколько элементов взять из массива A\n",
        "__device__ int merge_path_search(const int* A, int aCount,\n",
        "                                 const int* B, int bCount,\n",
        "                                 int diag) {\n",
        "\n",
        "    // Диапазон бинарного поиска\n",
        "    int lo = max(0, diag - bCount);\n",
        "    int hi = min(diag, aCount);\n",
        "\n",
        "    // Бинарный поиск границы слияния\n",
        "    while (lo < hi) {\n",
        "        int mid = (lo + hi) >> 1;\n",
        "        int j = diag - mid;\n",
        "\n",
        "        // Граничные значения\n",
        "        int A_left  = (mid > 0) ? A[mid - 1] : INT_MIN;\n",
        "        int A_right = (mid < aCount) ? A[mid] : INT_MAX;\n",
        "        int B_left  = (j > 0) ? B[j - 1] : INT_MIN;\n",
        "        int B_right = (j < bCount) ? B[j] : INT_MAX;\n",
        "\n",
        "        if (A_left > B_right) hi = mid;\n",
        "        else if (B_left >= A_right) lo = mid + 1;\n",
        "        else return mid;\n",
        "    }\n",
        "    return lo;\n",
        "}\n",
        "\n",
        "// CUDA-ядро: слияние двух отсортированных участков\n",
        "__global__ void merge_pass(const int* in, int* out, int n, int width) {\n",
        "\n",
        "    // Каждый CUDA-блок обрабатывает одну пару подмассивов\n",
        "    int pair = (int)blockIdx.x;\n",
        "    int left = pair * (2 * width);\n",
        "    if (left >= n) return;\n",
        "\n",
        "    // Границы двух массивов\n",
        "    int mid   = left + width;\n",
        "    int right = min(left + 2 * width, n);\n",
        "\n",
        "    int aCount = min(width, n - left);\n",
        "    int bCount = max(0, right - mid);\n",
        "\n",
        "    // Указатели на левый и правый массив\n",
        "    const int* A = in + left;\n",
        "    const int* B = in + mid;\n",
        "\n",
        "    int total = aCount + bCount;\n",
        "\n",
        "    // Индекс потока и шаг по диагонали\n",
        "    int tid = (int)threadIdx.x;\n",
        "    int stride = (int)blockDim.x;\n",
        "\n",
        "    // Каждый поток вычисляет несколько элементов результата\n",
        "    for (int diag = tid; diag < total; diag += stride) {\n",
        "\n",
        "        // Находим позицию в A и B\n",
        "        int i = merge_path_search(A, aCount, B, bCount, diag);\n",
        "        int j = diag - i;\n",
        "\n",
        "        // Берём минимальный из двух кандидатов\n",
        "        int aVal = (i < aCount) ? A[i] : INT_MAX;\n",
        "        int bVal = (j < bCount) ? B[j] : INT_MAX;\n",
        "\n",
        "        out[left + diag] = (aVal <= bVal) ? aVal : bVal;\n",
        "    }\n",
        "}\n",
        "\n",
        "// GPU QUICK SORT PER CHUNK\n",
        "// Каждый CUDA-блок сортирует один chunk массива.\n",
        "// Разделение по pivot выполняется параллельно потоками.\n",
        "// После этого quicksort рекурсивно сортирует части.\n",
        "\n",
        "constexpr int CHUNK = 1024;          // размер chunk'а\n",
        "constexpr int INSERTION_CUTOFF = 32; // маленькие диапазоны -> insertion sort\n",
        "\n",
        "// Insertion sort для маленьких диапазонов (GPU)\n",
        "__device__ __forceinline__\n",
        "void insertion_sort(int* a, int l, int r) {\n",
        "    for (int i = l + 1; i <= r; ++i) {\n",
        "        int key = a[i];\n",
        "        int j = i - 1;\n",
        "        while (j >= l && a[j] > key) {\n",
        "            a[j + 1] = a[j];\n",
        "            --j;\n",
        "        }\n",
        "        a[j + 1] = key;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA-ядро: параллельный quicksort одного chunk'а\n",
        "__global__ void chunk_quick_sort_parallel(const int* in, int* out, int n) {\n",
        "\n",
        "    // Shared memory для chunk'а\n",
        "    __shared__ int s[CHUNK];\n",
        "    __shared__ int tmp[CHUNK];\n",
        "\n",
        "    // Начальный индекс chunk'а\n",
        "    int base = (int)blockIdx.x * CHUNK;\n",
        "    int tid  = (int)threadIdx.x;\n",
        "\n",
        "    // Загружаем данные из глобальной памяти в shared\n",
        "    for (int i = tid; i < CHUNK; i += (int)blockDim.x) {\n",
        "        int idx = base + i;\n",
        "        s[i] = (idx < n) ? in[idx] : INT_MAX;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Итеративный quicksort (через стек)\n",
        "    __shared__ int lstack[64]; // левая граница\n",
        "    __shared__ int rstack[64]; // правая граница\n",
        "    __shared__ int top;        // указатель стека\n",
        "\n",
        "    // Инициализация стека (делает 1 поток)\n",
        "    if (tid == 0) {\n",
        "        top = 0;\n",
        "        lstack[0] = 0;\n",
        "        rstack[0] = CHUNK - 1;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Основной цикл quicksort\n",
        "    while (true) {\n",
        "        int l, r;\n",
        "\n",
        "        // Один поток извлекает диапазон из стека\n",
        "        if (tid == 0) {\n",
        "            if (top < 0) {\n",
        "                l = r = -1; // сигнал выхода\n",
        "            } else {\n",
        "                l = lstack[top];\n",
        "                r = rstack[top];\n",
        "                top--;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Рассылаем l и r всем потокам\n",
        "        __shared__ int curL, curR;\n",
        "        if (tid == 0) { curL = l; curR = r; }\n",
        "        __syncthreads();\n",
        "\n",
        "        l = curL; r = curR;\n",
        "        if (l < 0) break;\n",
        "        if (r - l + 1 <= 1) continue;\n",
        "\n",
        "        // Маленький диапазон — insertion sort\n",
        "        if (r - l + 1 <= INSERTION_CUTOFF) {\n",
        "            if (tid == 0) insertion_sort(s, l, r);\n",
        "            __syncthreads();\n",
        "            continue;\n",
        "        }\n",
        "\n",
        "        // Выбор опорного элемента (pivot)\n",
        "        int pivot = s[(l + r) >> 1];\n",
        "\n",
        "        // Параллельное разбиение по pivot\n",
        "        __shared__ int lessCount, equalCount, greaterCount;\n",
        "        if (tid == 0) { lessCount = 0; equalCount = 0; greaterCount = 0; }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Каждый поток обрабатывает часть элементов\n",
        "        for (int i = l + tid; i <= r; i += (int)blockDim.x) {\n",
        "            int v = s[i];\n",
        "            if (v < pivot) {\n",
        "                int pos = atomicAdd(&lessCount, 1);\n",
        "                tmp[l + pos] = v;\n",
        "            } else if (v > pivot) {\n",
        "                int pos = atomicAdd(&greaterCount, 1);\n",
        "                tmp[r - pos] = v;\n",
        "            } else {\n",
        "                int pos = atomicAdd(&equalCount, 1);\n",
        "                tmp[l + pos] = v;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Подсчёт размеров подмассивов\n",
        "        __shared__ int Lc, Ec, Gc;\n",
        "        if (tid == 0) { Lc = lessCount; Ec = equalCount; Gc = greaterCount; }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Вторая фаза: корректная перестановка элементов\n",
        "        __shared__ int wLess, wEq, wGt;\n",
        "        if (tid == 0) { wLess = 0; wEq = 0; wGt = 0; }\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int i = l + tid; i <= r; i += (int)blockDim.x) {\n",
        "            int v = s[i];\n",
        "            if (v < pivot) {\n",
        "                int pos = atomicAdd(&wLess, 1);\n",
        "                tmp[l + pos] = v;\n",
        "            } else if (v == pivot) {\n",
        "                int pos = atomicAdd(&wEq, 1);\n",
        "                tmp[l + Lc + pos] = v;\n",
        "            } else {\n",
        "                int pos = atomicAdd(&wGt, 1);\n",
        "                tmp[r - pos] = v;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Копируем результат разбиения обратно\n",
        "        for (int i = l + tid; i <= r; i += (int)blockDim.x) {\n",
        "            s[i] = tmp[i];\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Добавляем новые поддиапазоны в стек\n",
        "        if (tid == 0) {\n",
        "            int leftL = l;\n",
        "            int leftR = l + Lc - 1;\n",
        "            int rightL = l + Lc + Ec;\n",
        "            int rightR = r;\n",
        "\n",
        "            int leftSize  = leftR - leftL + 1;\n",
        "            int rightSize = rightR - rightL + 1;\n",
        "\n",
        "            if (leftSize > 1 && rightSize > 1) {\n",
        "                if (leftSize < rightSize) {\n",
        "                    top++; lstack[top] = rightL; rstack[top] = rightR;\n",
        "                    top++; lstack[top] = leftL;  rstack[top] = leftR;\n",
        "                } else {\n",
        "                    top++; lstack[top] = leftL;  rstack[top] = leftR;\n",
        "                    top++; lstack[top] = rightL; rstack[top] = rightR;\n",
        "                }\n",
        "            } else if (leftSize > 1) {\n",
        "                top++; lstack[top] = leftL; rstack[top] = leftR;\n",
        "            } else if (rightSize > 1) {\n",
        "                top++; lstack[top] = rightL; rstack[top] = rightR;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Записываем отсортированный chunk в глобальную память\n",
        "    for (int i = tid; i < CHUNK; i += (int)blockDim.x) {\n",
        "        int idx = base + i;\n",
        "        if (idx < n) out[idx] = s[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// HOST: обёртка GPU quick sort + merge\n",
        "void gpu_quick_sort(std::vector<int>& a, float& ms_total) {\n",
        "\n",
        "    int n = (int)a.size();\n",
        "    if (n == 0) { ms_total = 0; return; }\n",
        "\n",
        "    int* d_in  = nullptr;\n",
        "    int* d_tmp = nullptr;\n",
        "\n",
        "    // Выделяем память на GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d_in,  n * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_tmp, n * sizeof(int)));\n",
        "\n",
        "    // Копируем данные с CPU на GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_in, a.data(), n * sizeof(int),\n",
        "                          cudaMemcpyHostToDevice));\n",
        "\n",
        "    // CUDA события для измерения времени\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "    // 1) Параллельная сортировка chunk'ов\n",
        "    int numChunks = (n + CHUNK - 1) / CHUNK;\n",
        "    chunk_quick_sort_parallel<<<numChunks, 256>>>(d_in, d_tmp, n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "\n",
        "    // 2) Слияние отсортированных chunk'ов\n",
        "    int* src = d_tmp;\n",
        "    int* dst = d_in;\n",
        "\n",
        "    for (int width = CHUNK; width < n; width <<= 1) {\n",
        "        int numPairs = (n + 2 * width - 1) / (2 * width);\n",
        "        merge_pass<<<numPairs, 256>>>(src, dst, n, width);\n",
        "        CUDA_CHECK(cudaGetLastError());\n",
        "        std::swap(src, dst);\n",
        "    }\n",
        "\n",
        "    // Останавливаем таймер GPU\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&ms_total, start, stop));\n",
        "\n",
        "    // Копируем результат обратно на CPU\n",
        "    CUDA_CHECK(cudaMemcpy(a.data(), src, n * sizeof(int),\n",
        "                          cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Освобождаем ресурсы\n",
        "    CUDA_CHECK(cudaEventDestroy(start));\n",
        "    CUDA_CHECK(cudaEventDestroy(stop));\n",
        "    CUDA_CHECK(cudaFree(d_in));\n",
        "    CUDA_CHECK(cudaFree(d_tmp));\n",
        "}\n",
        "// MAIN\n",
        "int main() {\n",
        "\n",
        "    // Размеры массивов для экспериментов\n",
        "    std::vector<int> sizes = {10000, 100000, 1000000};\n",
        "\n",
        "    // Генератор случайных чисел\n",
        "    std::mt19937 rng(12345);\n",
        "    std::uniform_int_distribution<int> dist(0, 1000000);\n",
        "\n",
        "    for (int N : sizes) {\n",
        "\n",
        "        // Формируем входной массив\n",
        "        std::vector<int> a(N);\n",
        "        for (int i = 0; i < N; ++i)\n",
        "            a[i] = dist(rng);\n",
        "\n",
        "        // Копия для CPU-сортировки\n",
        "        std::vector<int> ref = a;\n",
        "\n",
        "        // CPU сортировка и замер времени\n",
        "        auto t0 = std::chrono::high_resolution_clock::now();\n",
        "        std::sort(ref.begin(), ref.end());\n",
        "        auto t1 = std::chrono::high_resolution_clock::now();\n",
        "        double cpu_ms =\n",
        "            std::chrono::duration<double, std::milli>(t1 - t0).count();\n",
        "\n",
        "        // GPU сортировка\n",
        "        float gpu_ms = 0.0f;\n",
        "        gpu_quick_sort(a, gpu_ms);\n",
        "\n",
        "        // Проверка корректности\n",
        "        bool ok = (a == ref) && is_sorted_cpu(a);\n",
        "\n",
        "        // Вывод результатов\n",
        "        std::cout << \"\\nN = \" << N << \"\\n\";\n",
        "        std::cout << \"CPU std::sort (reference): \" << cpu_ms << \" ms\\n\";\n",
        "        std::cout << \"GPU QuickSort (CUDA): \" << gpu_ms << \" ms\\n\";\n",
        "        std::cout << \"Correct: \" << (ok ? \"YES\" : \"NO\") << \"\\n\";\n",
        "        if (gpu_ms > 0)\n",
        "            std::cout << \"Speedup CPU/GPU: \"\n",
        "                      << (cpu_ms / gpu_ms) << \"x\\n\";\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIRZxWARM9eD",
        "outputId": "02117dd6-f965-4719-fa67-699cf6d6b53d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 2main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O2 -arch=sm_75 2main.cu -o 2main #компиляция CUDA-программы\n",
        "!./2main #запуск программы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Ly3sITNhSS",
        "outputId": "e615a484-1d2d-4668-fce2-0fd098b6faa4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m2main.cu(215)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"Gc\"\u001b[0m was set but never used\n",
            "          __attribute__((shared)) int Lc, Ec, Gc;\n",
            "                                              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\n",
            "N = 10000\n",
            "CPU std::sort (reference): 0.653538 ms\n",
            "GPU QuickSort (CUDA): 1.45328 ms\n",
            "Correct: YES\n",
            "Speedup CPU/GPU: 0.449699x\n",
            "\n",
            "N = 100000\n",
            "CPU std::sort (reference): 13.5405 ms\n",
            "GPU QuickSort (CUDA): 5.38218 ms\n",
            "Correct: YES\n",
            "Speedup CPU/GPU: 2.51581x\n",
            "\n",
            "N = 1000000\n",
            "CPU std::sort (reference): 81.4596 ms\n",
            "GPU QuickSort (CUDA): 62.932 ms\n",
            "Correct: YES\n",
            "Speedup CPU/GPU: 1.29441x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание\n",
        "\n",
        "3. Реализовать параллельную пирамидальную сортировку на CUDA:\n",
        "\n",
        "● Постройте кучу и выполняйте извлечение элементов параллельно, где\n",
        "это возможно."
      ],
      "metadata": {
        "id": "K1RXGiO92bnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "4. Сравнение производительности:\n",
        "\n",
        "● Реализуйте последовательные версии этих алгоритмов на CPU.\n",
        "\n",
        "● Измерьте время выполнения каждой сортировки на CPU и на GPU для\n",
        "массивов разного размера (например, 10,000, 100,000 и 1,000,000\n",
        "элементов).\n",
        "\n",
        "● Сравните производительность и сделайте выводы."
      ],
      "metadata": {
        "id": "RJxU5qRv2vvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 3main.cu\n",
        "// Основной CUDA Runtime API\n",
        "#include <cuda_runtime.h>\n",
        "// Доступ к threadIdx, blockIdx, blockDim\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "// Стандартные библиотеки C++\n",
        "#include <algorithm>   // make_heap, sort_heap\n",
        "#include <chrono>      // измерение времени\n",
        "#include <climits>     // INT_MAX\n",
        "#include <iostream>    // cout\n",
        "#include <random>      // генератор случайных чисел\n",
        "#include <vector>      // std::vector\n",
        "\n",
        "// Макрос для проверки ошибок CUDA\n",
        "// После каждого вызова CUDA проверяем,\n",
        "// не возникла ли ошибка выполнения\n",
        "#define CUDA_CHECK(call) do {                                \\\n",
        "    cudaError_t e = (call);                                  \\\n",
        "    if (e != cudaSuccess) {                                  \\\n",
        "        std::cerr << \"CUDA error: \"                           \\\n",
        "                  << cudaGetErrorString(e)                    \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__    \\\n",
        "                  << std::endl;                               \\\n",
        "        std::exit(1);                                        \\\n",
        "    }                                                        \\\n",
        "} while(0)\n",
        "\n",
        "// Проверка отсортированности массива (CPU)\n",
        "static bool is_sorted_cpu(const std::vector<int>& a) {\n",
        "    // Проверяем, что каждый следующий элемент\n",
        "    // не меньше предыдущего\n",
        "    for (size_t i = 1; i < a.size(); ++i)\n",
        "        if (a[i - 1] > a[i]) return false;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "// DEVICE-ФУНКЦИЯ: sift-down (heapify) для одного узла\n",
        "// Восстанавливает свойство max-кучи, начиная с вершины i\n",
        "// Работает полностью на GPU\n",
        "__device__ void sift_down(int* arr, int n, int i) {\n",
        "    while (true) {\n",
        "        // Предполагаем, что текущий узел — максимальный\n",
        "        int largest = i;\n",
        "\n",
        "        // Индексы левого и правого потомков\n",
        "        int l = 2 * i + 1;\n",
        "        int r = 2 * i + 2;\n",
        "\n",
        "        // Если левый потомок больше — обновляем largest\n",
        "        if (l < n && arr[l] > arr[largest]) largest = l;\n",
        "        // Если правый потомок больше — обновляем largest\n",
        "        if (r < n && arr[r] > arr[largest]) largest = r;\n",
        "\n",
        "        // Если текущий элемент уже максимальный — выходим\n",
        "        if (largest == i) break;\n",
        "\n",
        "        // Иначе меняем местами текущий элемент и больший потомок\n",
        "        int tmp = arr[i];\n",
        "        arr[i] = arr[largest];\n",
        "        arr[largest] = tmp;\n",
        "\n",
        "        // Продолжаем sift-down с новой позиции\n",
        "        i = largest;\n",
        "    }\n",
        "}\n",
        "\n",
        "// KERNEL 1: параллельная heapify одного уровня\n",
        "// Каждый поток обрабатывает ОДИН узел кучи\n",
        "__global__ void heapify_level(int* arr, int n, int start, int end) {\n",
        "\n",
        "    // Глобальный индекс узла, который обрабатывает поток\n",
        "    int idx = start + blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Если индекс попадает в диапазон текущего уровня\n",
        "    if (idx <= end) {\n",
        "        // Восстанавливаем свойство кучи для этого узла\n",
        "        sift_down(arr, n, idx);\n",
        "    }\n",
        "}\n",
        "\n",
        "// KERNEL 2: извлечение максимума из кучи\n",
        "// Выполняется последовательно (1 поток),\n",
        "// так как извлечение корня — inherently sequential\n",
        "__global__ void extract_max(int* arr, int heapSize) {\n",
        "\n",
        "    // Используем только один поток\n",
        "    if (blockIdx.x == 0 && threadIdx.x == 0) {\n",
        "\n",
        "        // Индекс последнего элемента в куче\n",
        "        int last = heapSize - 1;\n",
        "\n",
        "        // Меняем местами корень (максимум) и последний элемент\n",
        "        int tmp = arr[0];\n",
        "        arr[0] = arr[last];\n",
        "        arr[last] = tmp;\n",
        "\n",
        "        // Восстанавливаем свойство кучи\n",
        "        sift_down(arr, heapSize - 1, 0);\n",
        "    }\n",
        "}\n",
        "\n",
        "// HOST-ФУНКЦИЯ: GPU Heap Sort\n",
        "void gpu_heap_sort(std::vector<int>& a, float& gpu_ms) {\n",
        "\n",
        "    int n = (int)a.size();\n",
        "    if (n == 0) { gpu_ms = 0; return; }\n",
        "\n",
        "    int* d = nullptr;\n",
        "\n",
        "    // Выделяем память на GPU\n",
        "    CUDA_CHECK(cudaMalloc(&d, n * sizeof(int)));\n",
        "\n",
        "    // Копируем массив с CPU на GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d, a.data(), n * sizeof(int),\n",
        "                          cudaMemcpyHostToDevice));\n",
        "\n",
        "    // CUDA-события для измерения времени GPU\n",
        "    cudaEvent_t start, stop;\n",
        "    CUDA_CHECK(cudaEventCreate(&start));\n",
        "    CUDA_CHECK(cudaEventCreate(&stop));\n",
        "    CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "    // 1) ПОСТРОЕНИЕ КУЧИ (bottom-up heapify)\n",
        "    // Индекс последнего внутреннего узла\n",
        "    int lastInternal = (n / 2) - 1;\n",
        "\n",
        "    // Обрабатываем уровни кучи снизу вверх\n",
        "    for (int levelEnd = lastInternal; levelEnd >= 0; ) {\n",
        "\n",
        "        // Определяем границы текущего уровня\n",
        "        int levelStart = max(0, (levelEnd - (levelEnd + 1) / 2));\n",
        "        int count = levelEnd - levelStart + 1;\n",
        "\n",
        "        // Параметры запуска CUDA-ядра\n",
        "        int threads = 256;\n",
        "        int blocks = (count + threads - 1) / threads;\n",
        "\n",
        "        // Параллельно heapify все узлы текущего уровня\n",
        "        heapify_level<<<blocks, threads>>>(d, n, levelStart, levelEnd);\n",
        "        CUDA_CHECK(cudaGetLastError());\n",
        "\n",
        "        // Переходим к следующему уровню выше\n",
        "        levelEnd = levelStart - 1;\n",
        "    }\n",
        "\n",
        "    // 2) ПОСЛЕДОВАТЕЛЬНОЕ ИЗВЛЕЧЕНИЕ ЭЛЕМЕНТОВ\n",
        "    for (int heapSize = n; heapSize > 1; --heapSize) {\n",
        "        extract_max<<<1, 1>>>(d, heapSize);\n",
        "        CUDA_CHECK(cudaGetLastError());\n",
        "    }\n",
        "\n",
        "    // Останавливаем таймер GPU\n",
        "    CUDA_CHECK(cudaEventRecord(stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&gpu_ms, start, stop));\n",
        "\n",
        "    // Копируем результат обратно на CPU\n",
        "    CUDA_CHECK(cudaMemcpy(a.data(), d, n * sizeof(int),\n",
        "                          cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Освобождаем ресурсы\n",
        "    CUDA_CHECK(cudaEventDestroy(start));\n",
        "    CUDA_CHECK(cudaEventDestroy(stop));\n",
        "    CUDA_CHECK(cudaFree(d));\n",
        "}\n",
        "\n",
        "// MAIN: тестирование и сравнение CPU vs GPU\n",
        "int main() {\n",
        "\n",
        "    // Размеры массивов для экспериментов\n",
        "    std::vector<int> sizes = {10000, 100000, 1000000};\n",
        "\n",
        "    // Генератор случайных чисел\n",
        "    std::mt19937 rng(42);\n",
        "    std::uniform_int_distribution<int> dist(0, 1000000);\n",
        "\n",
        "    for (int N : sizes) {\n",
        "\n",
        "        // Формируем входной массив\n",
        "        std::vector<int> a(N);\n",
        "        for (int i = 0; i < N; ++i)\n",
        "            a[i] = dist(rng);\n",
        "\n",
        "        // Копия массива для CPU-версии\n",
        "        std::vector<int> ref = a;\n",
        "\n",
        "        // CPU Heap Sort + замер времени\n",
        "        auto t0 = std::chrono::high_resolution_clock::now();\n",
        "        std::make_heap(ref.begin(), ref.end());\n",
        "        std::sort_heap(ref.begin(), ref.end());\n",
        "        auto t1 = std::chrono::high_resolution_clock::now();\n",
        "        double cpu_ms =\n",
        "            std::chrono::duration<double, std::milli>(t1 - t0).count();\n",
        "\n",
        "        // GPU Heap Sort\n",
        "        float gpu_ms = 0.0f;\n",
        "        gpu_heap_sort(a, gpu_ms);\n",
        "\n",
        "        // Проверка корректности результата\n",
        "        bool ok = (a == ref) && is_sorted_cpu(a);\n",
        "\n",
        "        // Вывод результатов\n",
        "        std::cout << \"\\nN = \" << N << \"\\n\";\n",
        "        std::cout << \"CPU HeapSort: \" << cpu_ms << \" ms\\n\";\n",
        "        std::cout << \"GPU HeapSort (parallel heapify): \" << gpu_ms << \" ms\\n\";\n",
        "        std::cout << \"Correct: \" << (ok ? \"YES\" : \"NO\") << \"\\n\";\n",
        "        if (gpu_ms > 0)\n",
        "            std::cout << \"Speedup CPU/GPU: \"\n",
        "                      << (cpu_ms / gpu_ms) << \"x\\n\";\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNDvK5MSzxMn",
        "outputId": "1302845c-d64c-4235-e5c5-01fbbefce0a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 3main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O2 -arch=sm_75 3main.cu -o 3main #компиляция CUDA-программы\n",
        "!./3main #запуск программы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCYr4yn5z1Bg",
        "outputId": "53aa267b-3458-4876-baab-76d6af7fb624"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "N = 10000\n",
            "CPU HeapSort: 2.96151 ms\n",
            "GPU HeapSort (parallel heapify): 101.591 ms\n",
            "Correct: NO\n",
            "Speedup CPU/GPU: 0.0291513x\n",
            "\n",
            "N = 100000\n",
            "CPU HeapSort: 14.6757 ms\n",
            "GPU HeapSort (parallel heapify): 634.485 ms\n",
            "Correct: NO\n",
            "Speedup CPU/GPU: 0.02313x\n",
            "\n",
            "N = 1000000\n",
            "CPU HeapSort: 133.847 ms\n",
            "GPU HeapSort (parallel heapify): 6102.69 ms\n",
            "Correct: NO\n",
            "Speedup CPU/GPU: 0.0219325x\n"
          ]
        }
      ]
    }
  ]
}