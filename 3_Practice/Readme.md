# Состав проекта
Все решения данной практической работы реализованы и выполнены в одном файле Practice_3.ipynb

*Причины использования Google Colab:*
* Он предоставляет доступ к видеокарте NVIDIA (Tesla T4), необходимой для выполнения CUDA-программ.

* В среде Colab уже установлены и настроены CUDA Toolkit и компилятор nvcc, что позволяет компилировать и запускать CUDA-код без дополнительной настройки.

## Ответы на контрольные вопросы:

## 1. В чем различие между последовательной и параллельной реализациями сортировки слиянием?

Последовательная реализация сортировки слиянием выполняет все этапы алгоритма (разделение массива и слияние подмассивов) в одном потоке, последовательно обрабатывая данные.
Параллельная реализация распределяет сортировку подмассивов между несколькими потоками или вычислительными ядрами, что позволяет выполнять сортировку и слияние одновременно. Это может значительно сократить время выполнения для больших массивов, но требует дополнительных затрат на синхронизацию и управление потоками.

## 2. Как распределение потоков и блоков влияет на производительность на CUDA?

Распределение потоков и блоков напрямую влияет на загрузку GPU. Если потоков слишком мало, вычислительные ресурсы GPU используются неэффективно. Если потоков слишком много или размер блоков выбран неправильно, возникают накладные расходы на планирование и доступ к памяти. Оптимальное распределение потоков и блоков позволяет скрыть задержки доступа к памяти и максимально использовать параллелизм GPU.

## 3. Какие сложности возникают при реализации быстрой сортировки на GPU?

Основные сложности связаны с рекурсивной природой быстрой сортировки и неравномерным разделением данных. На GPU сложно эффективно реализовать рекурсию и динамическое разбиение массива, так как это приводит к неравномерной загрузке потоков и дополнительным затратам на синхронизацию. Также усложняется управление памятью и обмен данными между потоками.

## 4. В каких случаях параллельная реализация сортировки на GPU может быть менее эффективной, чем на CPU?

Параллельная сортировка на GPU может быть менее эффективной для небольших массивов данных, когда накладные расходы на копирование данных между CPU и GPU превышают выигрыш от параллельных вычислений. Также при алгоритмах с большим количеством ветвлений и зависимостей между элементами CPU может показать лучшую производительность.

## 5. Почему важно правильно выбирать размер блоков и потоков в CUDA?

Правильный выбор размера блоков и потоков позволяет эффективно использовать вычислительные ресурсы GPU. Слишком маленькие блоки приводят к недостаточной загрузке GPU, а слишком большие — к превышению доступных ресурсов (регистров и разделяемой памяти). Оптимальный размер блоков помогает снизить задержки и повысить общую производительность программы.

## 6. Как использование разделяемой памяти может повлиять на производительность сортировки?

Разделяемая память значительно быстрее глобальной памяти GPU. Использование разделяемой памяти позволяет уменьшить количество обращений к глобальной памяти, что ускоряет выполнение сортировки. Однако объем разделяемой памяти ограничен, поэтому её неправильное использование может привести к снижению производительности или невозможности запуска ядра.

## 7. Что означает принцип "разделяй и властвуй" в контексте алгоритмов сортировки?

Принцип «разделяй и властвуй» означает разбиение исходной задачи сортировки на несколько меньших подзадач, их независимое решение и последующее объединение результатов. В алгоритмах сортировки (например, сортировка слиянием и быстрая сортировка) массив разбивается на подмассивы, которые сортируются отдельно, а затем объединяются в отсортированный массив.
